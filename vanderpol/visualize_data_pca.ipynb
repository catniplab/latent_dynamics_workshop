{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizing synthetic data created using Van der Pol Oscillator dynamics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import h5py\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "from einops import rearrange\n",
    "\n",
    "# local imports\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from code_pack.plotting import plot_two_d_vector_field_from_data, raster_to_events\n",
    "from code_pack.generate_vdp_data import generate_van_der_pol, generate_noisy_van_der_pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider an Euler discretization of a Van der Pol oscillator with noisy transitions:\n",
    "\n",
    "$z_{t+1,1} = z_{t,1} + \\tau_1^{-1} \\Delta z_{t,2} + \\sigma \\epsilon$\\\n",
    "$z_{t+1,2} = z_{t,2} + \\tau_2^{-1} \\Delta(\\mu (1-z_{t,1})^2 z_{t,2} - z_{t,1}) + \\sigma \\epsilon$\n",
    "\n",
    "and Poisson observations:\n",
    "\n",
    "$y_{n,t} \\sim \\text{Poisson}(y_{n,t} \\mid \\Delta \\exp(C_n^\\top z_t + b_n))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from ./data/vdp_noisy.h5\n",
    "file_name = \"data/poisson_obs.h5\"\n",
    "\n",
    "# dynamics parameters\n",
    "data = h5py.File(file_name, 'r')\n",
    "system_parameters = {}\n",
    "system_parameters['mu'] = data['mu']\n",
    "system_parameters['tau_1'] = data['tau_1']\n",
    "system_parameters['tau_2'] = data['tau_2']\n",
    "system_parameters['sigma'] = data['sigma']\n",
    "system_parameters['scale'] = np.array(data['scale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizationing trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting trajectories of the dataset\n",
    "X = np.array(data['X'])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "_ = ax.plot(X[0,:,0], X[0,:,1])\n",
    "ax.scatter(X[0, 0, 0], X[0, 0, 1], marker='o', color='red', zorder=10, s=100, label='start')\n",
    "ax.scatter(X[0, -1, 0], X[0, -1, 1], marker='x', color='red', zorder=10, s=100, label='end')\n",
    "\n",
    "# system_parameters_copy = copy.deepcopy(system_parameters)\n",
    "system_parameters['sigma'] = 0.0\n",
    "dynamic_func = lambda inp : generate_noisy_van_der_pol(inp, np.array([0.0, 5e-3]), system_parameters)\n",
    "axs_range = {'x_min':-1.5, 'x_max':1.5, 'y_min':-1.5, 'y_max':1.5}\n",
    "plot_two_d_vector_field_from_data(dynamic_func, ax, axs_range)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('sample trajectory (true state)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Effect of tuning function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_tilde = np.array(data['C_tilde'])\n",
    "idx = np.lexsort((C_tilde[:,0], C_tilde[:,1]), axis=0) # sort the loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# showing the spike raster generated from noisy Vdp\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 3), sharex=True, sharey=True)\n",
    "events = raster_to_events(np.array(data['Y'])[0,:,:])\n",
    "events_softplus = raster_to_events(np.array(data['Y_softplus'])[0,:,:])\n",
    "events_axis_aligned = raster_to_events(np.array(data['Y_axis'])[0,:,idx].transpose())\n",
    "axs[0].eventplot(events, linewidths=0.5, color='blue');\n",
    "axs[1].eventplot(events_softplus, linewidths=0.5, color='blue');\n",
    "axs[2].eventplot(events_axis_aligned, linewidths=0.5, color='blue');\n",
    "axs[0].set_title(f'$\\exp()$');\n",
    "axs[1].set_title(f'softplus$()$');\n",
    "axs[2].set_title(f'axis aligned');\n",
    "axs[0].set_xlabel(\"Time\");\n",
    "axs[0].set_ylabel(\"Neuron\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "The first latent variable model that most people become familiar with is PCA.\n",
    "Before performing PCA, we smooth the spikes with a Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing data with a gaussian kernel\n",
    "data_stacked = rearrange(np.array(data['Y']), 'trial time neurons -> (trial neurons) time')\n",
    "data_smooth = scipy.ndimage.gaussian_filter1d(input = data_stacked, sigma=50.0, axis=1)\n",
    "data_smooth = rearrange(data_smooth, '(trial neurons) time -> (trial time) neurons', trial=250, neurons=250) # TODO: hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_centered = data_smooth - np.mean(data_smooth, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidx = slice(500,1000)\n",
    "fig, ax = plt.subplots(1, 1, figsize =(10, 5))\n",
    "ax.plot(data_centered[tidx, 0:3]);\n",
    "ax.set_xlabel(\"Time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA using SVD\n",
    "u, s, vh = np.linalg.svd(data_centered, full_matrices=False)\n",
    "u.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_sv = s**2/np.sum(s**2)\n",
    "top2sv = np.sum(norm_sv[:2])\n",
    "print(\"Total observations explained by the first two principal components: {0:.3f}%\".format(top2sv*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "axs[0].plot(norm_sv * 100, 'o-')\n",
    "axs[1].plot(norm_sv.cumsum() * 100, 'o-')\n",
    "axs[1].set_ylim([0, 100])\n",
    "axs[2].plot(20*np.log10(norm_sv), 'o-')\n",
    "\n",
    "[(axs[k].grid(), axs[k].set_title(f'')) for k in range(3)]\n",
    "axs[0].set_ylabel(\"Variance explained per PC ($\\%$)\"); \n",
    "axs[1].set_ylabel(\"Cumulative variance explained ($\\%$)\");\n",
    "axs[2].set_ylabel(\"Variance explained (dB)\"); \n",
    "axs[0].set_xlabel(\"PC (ordered)\");\n",
    "axs[1].set_xlabel(\"PC (ordered)\");\n",
    "axs[2].set_xlabel(\"PC (ordered)\");\n",
    "fig.suptitle(\"What's the dimensionality? Inspecting variance explained by each PC defined dim\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing top two PCs\n",
    "top2u = u[:, :2]\n",
    "top2s = s[:2]\n",
    "top2reconstruction = top2u * top2s\n",
    "print(top2reconstruction.shape)\n",
    "fig, ax = plt.subplots(1, 1, figsize =(10, 5))\n",
    "ax.plot(top2reconstruction[tidx, 0], color='blue', label='PC 1')\n",
    "ax.plot(top2reconstruction[tidx, 1], color='red', label='PC 2')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize =(10, 5))\n",
    "nTrial = 10\n",
    "cmap = matplotlib.colormaps['gist_rainbow'].resampled(nTrial)\n",
    "for trial in range(nTrial):\n",
    "    tidx = slice(500*trial, 500*(trial+1))\n",
    "    ax.plot(top2reconstruction[tidx, 0], top2reconstruction[tidx, 1], color=cmap(trial))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, _, _, _ = np.linalg.lstsq(top2reconstruction, X.reshape((-1,2)), rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = top2reconstruction @ A\n",
    "b = b.reshape((250,500,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize =(10, 5))\n",
    "trial=2\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.plot(b[trial, :, :], 'b', label=\"Reconstruction\")\n",
    "ax.plot(X[trial, :, :], 'r', label=\"Data\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize =(10, 5))\n",
    "nTrial = 2\n",
    "cmap = matplotlib.colormaps['gist_rainbow'].resampled(nTrial)\n",
    "for trial in range(nTrial):\n",
    "    ax.plot(b[trial, :, 0], b[trial, :, 1], color=cmap(trial))\n",
    "    ax.plot(X[trial, :, 0], X[trial, :, 1], '--', color=cmap(trial))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}