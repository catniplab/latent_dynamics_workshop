{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ALTbmnGoemgT",
   "metadata": {
    "id": "ALTbmnGoemgT"
   },
   "source": [
    "# Nonlinear State Space Modeling via XFADS - simulated ring attractor\n",
    "\n",
    "\n",
    "Dowling, M., Zhao, Y., & Park, I. M. (2024). eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling. The Thirty-Eighth Annual Conference on Neural Information Processing Systems. NeurIPS. https://openreview.net/forum?id=Ln8ogihZ2S\n",
    "\n",
    "XFADS is our favorite variational autoencoder for nonlinear state space modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ok-TCt-4IWj8",
   "metadata": {
    "id": "Ok-TCt-4IWj8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    _in_colab = True\n",
    "except:\n",
    "    _in_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fIUowr3Ikkl",
   "metadata": {
    "id": "0fIUowr3Ikkl"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Create a `build-system` for the `xfads` package from the `pyproject.toml`\n",
    "\n",
    "(If you are local, make sure to run this command in the terminal after cd'√≠ng to the project/ workshop main directory and activating the conda environment)\n",
    "\n",
    "`pip install -e xfads/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i34FFj7SIbHE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i34FFj7SIbHE",
    "outputId": "57b2daa2-b0e7-4d9f-9107-cdb7e99dcce8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if _in_colab:\n",
    "    !git clone --recurse-submodules https://github.com/catniplab/latent_dynamics_workshop.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fGE66k4UIbJI",
   "metadata": {
    "id": "fGE66k4UIbJI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if _in_colab:\n",
    "    sys.path.append(os.path.join(cwd, \"latent_dynamics_workshop\"))\n",
    "    sys.path.append(os.path.join(cwd, \"latent_dynamics_workshop/xfads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qh_s-NIiI4AD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh_s-NIiI4AD",
    "outputId": "9b16fd62-e8fe-4432-e530-fa735146401d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if _in_colab:\n",
    "    !pip install -e latent_dynamics_workshop/xfads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fDaXapziIaka",
   "metadata": {
    "id": "fDaXapziIaka",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xfads.utils as utils\n",
    "import xfads.plot_utils as plot_utils\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint\n",
    "\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics\n",
    "from xfads.ssm_modules.likelihoods import GaussianLikelihood\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "\n",
    "from xfads.smoothers.lightning_trainers import LightningNonlinearSSM\n",
    "from xfads.smoothers.nonlinear_smoother import NonlinearFilterSmallL, LowRankNonlinearStateSpaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29d5d4f2a7536",
   "metadata": {
    "id": "2ee29d5d4f2a7536"
   },
   "source": [
    "## ‚öôÔ∏è 2. Initialize Configuration\n",
    "\n",
    "We use Hydra to load experiment configs and set up deterministic behavior for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c27e664155363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:31:29.253455Z",
     "start_time": "2025-07-02T17:31:29.098163Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d7c27e664155363",
    "outputId": "abec47c0-6528-4728-ee81-c9a60a33d77d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "cfg_dict = {\n",
    "    # --- graphical model --- #\n",
    "    'n_latents': 2,\n",
    "    'n_latents_read': 2,\n",
    "    'rank_local': 2,\n",
    "    'rank_backward': 2,\n",
    "    'n_hidden_dynamics': 64,\n",
    "\n",
    "    # --- inference network --- #\n",
    "    'n_samples': 5,\n",
    "    'n_hidden_local': 128,\n",
    "    'n_hidden_backward': 64,\n",
    "\n",
    "    # --- hyperparameters --- #\n",
    "    'use_cd': False,\n",
    "    'p_mask_a': 0.8,\n",
    "    'p_mask_b': 0.0,\n",
    "    'p_mask_apb': 0.0,\n",
    "    'p_mask_y_in': 0.0,\n",
    "    'p_local_dropout': 0.4,\n",
    "    'p_backward_dropout': 0.0,\n",
    "    'lr_gamma_decay': 0.99,\n",
    "\n",
    "    # --- training --- #\n",
    "    'device': 'cpu',\n",
    "    'data_device': 'cpu',\n",
    "    'lr': 1e-3,\n",
    "    'n_epochs': 5,\n",
    "    'batch_sz': 128,\n",
    "\n",
    "    # --- misc --- #\n",
    "    'bin_sz': 20e-3,\n",
    "    'bin_sz_ms': 20,\n",
    "    'seed': 1234,\n",
    "    'default_dtype': torch.float32,\n",
    "}\n",
    "\n",
    "class Cfg(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self:\n",
    "            return self[attr]\n",
    "        else:\n",
    "            raise AttributeError(f\"'Cfg' object has no attribute '{attr}'\")\n",
    "\n",
    "cfg = Cfg(cfg_dict)\n",
    "\n",
    "# Set devices and seed\n",
    "if not torch.cuda.is_available():\n",
    "    cfg.device = 'cpu'\n",
    "    cfg.data_device = 'cpu'\n",
    "\n",
    "pl.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(cfg.default_dtype)\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oyjxd98x7zpy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyjxd98x7zpy",
    "outputId": "062248b9-3bc5-41eb-daf1-6f9eb45a957a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "cfg.device = device\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# A quick test\n",
    "matrix_a = torch.randn(1024, 1024, device=device)\n",
    "result = torch.matmul(matrix_a, matrix_a)\n",
    "\n",
    "# cfg['n_epochs'] = 50  # reduced epochs for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166b21e3be10cb2",
   "metadata": {
    "id": "5166b21e3be10cb2"
   },
   "source": [
    "## üìà 3. Simulate Data\n",
    "\n",
    "We generate data from a 2D ring attractor latent dynamic system, projecting into 100-dimensional observations using a fixed linear readout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb244a2edaa6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:31:31.453353Z",
     "start_time": "2025-07-02T17:31:31.049992Z"
    },
    "id": "ffb244a2edaa6d8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_trials = 3000\n",
    "n_neurons = 100\n",
    "n_time_bins = 75\n",
    "\n",
    "mean_fn = utils.RingAttractorDynamics(bin_sz=1e-1, w=0.0)\n",
    "C = utils.FanInLinear(cfg.n_latents, n_neurons, device=cfg.device).requires_grad_(False)\n",
    "\n",
    "Q_diag = 5e-3 * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1.0 * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "R_diag = 1e-1 * torch.ones(n_neurons, device=cfg.device)\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "\n",
    "z = utils.sample_gauss_z(mean_fn, Q_diag, m_0, Q_0_diag, n_trials, n_time_bins)\n",
    "y = C(z) + torch.sqrt(R_diag) * torch.randn((n_trials, n_time_bins, n_neurons), device=cfg.device)\n",
    "y = y.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807079c3ba83cee",
   "metadata": {
    "id": "8807079c3ba83cee"
   },
   "source": [
    "## üìà 4. Visualize Latent Trajectories\n",
    "\n",
    "Let's look at some sample trajectories from the 2D latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d352ca0ed99d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:14.577538Z",
     "start_time": "2025-07-02T19:44:12.295093Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "861d352ca0ed99d5",
    "outputId": "5585cf1f-07ee-45b6-96f9-09473bfee6ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 6))\n",
    "for i in range(40):\n",
    "    axs.plot(z[i, :, 0].cpu(), z[i, :, 1].cpu(), alpha=0.6, linewidth=0.5)\n",
    "\n",
    "plot_utils.plot_two_d_vector_field(mean_fn, axs, min_xy=-2, max_xy=2)\n",
    "axs.set_title(\"Sample Latent Trajectories (2D Ring Attractor)\")\n",
    "axs.set_xlabel(\"Latent dim 1\")\n",
    "axs.set_ylabel(\"Latent dim 2\")\n",
    "axs.set_xlim(-2, 2)\n",
    "axs.set_ylim(-2, 2)\n",
    "axs.set_box_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfaaf7d41583a4",
   "metadata": {
    "id": "f9cfaaf7d41583a4"
   },
   "source": [
    "##  5. Prepare Train/Validation Dataloaders\n",
    "\n",
    "Split the simulated data into training and validation sets and prepare PyTorch dataloaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0486dd107fdfad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:27.362064Z",
     "start_time": "2025-07-02T17:34:27.358468Z"
    },
    "id": "3f0486dd107fdfad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    elem = batch[0]\n",
    "    if isinstance(elem, (tuple, list)):\n",
    "        return tuple(torch.stack([b[i] for b in batch]).to(cfg.device) for i in range(len(elem)))\n",
    "    else:\n",
    "        return torch.stack(batch).to(cfg.device)\n",
    "\n",
    "y_train, z_train = y[:2*n_trials//3], z[:2*n_trials//3]\n",
    "y_valid, z_valid = y[2*n_trials//3:], z[2*n_trials//3:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(y_train), batch_size=cfg.batch_sz, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(y_valid), batch_size=cfg.batch_sz, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a019425d36406e",
   "metadata": {
    "id": "e0a019425d36406e"
   },
   "source": [
    "## üß± 6. Define Model Components\n",
    "\n",
    "We define the following:\n",
    "- A Gaussian likelihood with a fixed observation noise\n",
    "- A nonlinear Gaussian dynamics module\n",
    "- A prior over the initial condition\n",
    "- Local and backward encoders for amortized inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a0d03984446ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:28.493744Z",
     "start_time": "2025-07-02T17:34:28.155205Z"
    },
    "id": "2e9a0d03984446ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Likelihood\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, C)\n",
    "likelihood_pdf = GaussianLikelihood(readout_fn, n_neurons, R_diag, device=cfg.device, fix_R=True)\n",
    "\n",
    "# Dynamics\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)\n",
    "\n",
    "# Initial condition\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)\n",
    "\n",
    "# Encoders\n",
    "backward_encoder = BackwardEncoderLRMvn(\n",
    "    cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "    rank_local=cfg.rank_local, rank_backward=cfg.rank_backward, device=cfg.device\n",
    ")\n",
    "local_encoder = LocalEncoderLRMvn(\n",
    "    cfg.n_latents, n_neurons, cfg.n_hidden_local, cfg.n_latents,\n",
    "    rank=cfg.rank_local, device=cfg.device, dropout=cfg.p_local_dropout\n",
    ")\n",
    "\n",
    "# Nonlinear filtering\n",
    "nl_filter = NonlinearFilterSmallL(dynamics_mod, initial_condition_pdf, device=cfg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40405b7f1966f90a",
   "metadata": {
    "id": "40405b7f1966f90a"
   },
   "source": [
    "## üß† 7. Assemble the State Space Model\n",
    "\n",
    "We combine dynamics, likelihood, encoders, and filtering into a complete latent variable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449ba34d5b2aaa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:29.772353Z",
     "start_time": "2025-07-02T17:34:29.769558Z"
    },
    "id": "d449ba34d5b2aaa2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm = LowRankNonlinearStateSpaceModel(\n",
    "    dynamics_mod, likelihood_pdf, initial_condition_pdf,\n",
    "    backward_encoder, local_encoder, nl_filter, device=cfg.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726c69556e898d1",
   "metadata": {
    "id": "d726c69556e898d1"
   },
   "source": [
    "## üîÅ 8. Train the Model Using PyTorch Lightning\n",
    "\n",
    "We use `LightningNonlinearSSM` for training. Logging and checkpointing are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkmlKUzQmbTz",
   "metadata": {
    "id": "mkmlKUzQmbTz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Timer\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529df5e92cc355f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:31.024563Z",
     "start_time": "2025-07-02T17:34:31.005135Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393,
     "referenced_widgets": [
      "b548f1bb9e7b4ffea5cc574ca00755e9",
      "2d970c81e4ec4b26916da8450ca9e068"
     ]
    },
    "id": "529df5e92cc355f9",
    "outputId": "1ed11b8c-759d-47f4-bdb1-3f769ce69a0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_from_scratch = False\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if _in_colab:\n",
    "    log_path = 'latent_dynamics_workshop/logs/ring_attractor'\n",
    "    ckpts_path = 'latent_dynamics_workshop/ckpts/ring_attractor'\n",
    "else:\n",
    "    log_path = './logs/ring_attractor'\n",
    "    ckpts_path = './ckpts/ring_attractor'\n",
    "\n",
    "if train_from_scratch:\n",
    "    seq_vae = LightningNonlinearSSM(ssm, cfg)\n",
    "\n",
    "    csv_logger = CSVLogger(log_path, name=f'r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='noncausal')\n",
    "    ckpt_callback = ModelCheckpoint(\n",
    "        save_top_k=3, monitor='valid_loss', mode='min',\n",
    "        dirpath=ckpts_path, filename='{epoch:0}_{valid_loss:.2f}'\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg.n_epochs,\n",
    "        gradient_clip_val=1.0,\n",
    "        default_root_dir='lightning/',\n",
    "        callbacks=[RichProgressBar(), ckpt_callback, timer],\n",
    "        accelerator=cfg.device,  # disable autodetection (no MPS support!)\n",
    "        logger=csv_logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=seq_vae, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "    torch.save(ckpt_callback.best_model_path, f'{ckpts_path}/best_model_path.pt')\n",
    "\n",
    "else:\n",
    "    seq_vae = LightningNonlinearSSM.load_from_checkpoint(f'{ckpts_path}/example_model.ckpt', ssm=ssm, cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aXzym_zRdSzV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXzym_zRdSzV",
    "outputId": "faa12d91-9fba-4b2b-e552-483ff6f763fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(timer.time_elapsed(\"train\"))  # total training time\n",
    "print(timer.time_elapsed(\"validate\"))  # validation time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7d9f2fd34e1af",
   "metadata": {
    "id": "1bb7d9f2fd34e1af"
   },
   "source": [
    "## ‚úÖ Done!\n",
    "\n",
    "The model is now trained. You can proceed with:\n",
    "- Plotting smoothed trajectories.\n",
    "- Visualizing uncertainty.\n",
    "- Comparing inferred vs. ground truth latents (since this was a synthetic dataset).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef34e7cb93bc02",
   "metadata": {
    "id": "89ef34e7cb93bc02"
   },
   "source": [
    "## üåÄ 9. Visualize Learned Dynamics and Simulated Trajectories\n",
    "\n",
    "Now that training is complete, we can explore what the model has learned.  \n",
    "This section:\n",
    "- Seeds the latent space with initial conditions.\n",
    "- Rolls out the learned dynamics forward in time.\n",
    "- Overlays those trajectories onto the learned dynamics vector field.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7254c298d909a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:02.851607Z",
     "start_time": "2025-07-02T19:45:02.821724Z"
    },
    "id": "19d7254c298d909a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define number of rollout samples and rollout length\n",
    "n_ex_samples = 1\n",
    "n_ex_trials = 50\n",
    "n_ex_time_bins = 50\n",
    "\n",
    "# Sample initial latent states (z_0): a mix of small and large amplitude noise\n",
    "z_0 = torch.zeros((n_ex_samples, n_ex_trials, 2))\n",
    "z_0[:, ::2] = 0.2 * torch.randn_like(z_0[:, ::2])   # small amplitude for even-indexed trials\n",
    "z_0[:, 1::2] = 2.0 * torch.randn_like(z_0[:, 1::2])  # large amplitude for odd-indexed trials\n",
    "\n",
    "# Predict forward using the learned dynamics (no encoder or data used here)\n",
    "z_prd = seq_vae.ssm.predict_forward(z_0, n_ex_time_bins).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d07535c3a411d",
   "metadata": {
    "id": "996d07535c3a411d"
   },
   "source": [
    "### üß≠ Plot: Learned Dynamics Vector Field + Predicted Latent Trajectories\n",
    "\n",
    "The vector field shows the learned mean dynamics function.\n",
    "Each curve shows a rollout of the model's latent trajectory starting from a different `z_0`.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec996ab8b81f07bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:05.730298Z",
     "start_time": "2025-07-02T19:45:04.900025Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "ec996ab8b81f07bd",
    "outputId": "434ff5a9-e594-4652-9e77-7b535247db08",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 6))\n",
    "axs.set_box_aspect(1.0)\n",
    "axs.set_xlim(-2.0, 2.0)\n",
    "axs.set_ylim(-2.0, 2.0)\n",
    "axs.set_title(\"Learned Dynamics and Autonomous Latent Trajectories\")\n",
    "\n",
    "# Plot learned vector field over the 2D latent space\n",
    "plot_utils.plot_two_d_vector_field(\n",
    "    seq_vae.ssm.dynamics_mod.mean_fn,\n",
    "    axs,\n",
    "    min_xy=-2,\n",
    "    max_xy=2,\n",
    ")\n",
    "\n",
    "# Overlay predicted trajectories\n",
    "for i in range(50):  # plot 50 of the 50\n",
    "    axs.plot(z_prd[0, i, :, 0].cpu(), z_prd[0, i, :, 1].cpu(), lw=0.5, alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb212b3aeaa9f77",
   "metadata": {
    "id": "aeb212b3aeaa9f77"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d970c81e4ec4b26916da8450ca9e068": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b548f1bb9e7b4ffea5cc574ca00755e9": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_2d970c81e4ec4b26916da8450ca9e068",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4/4  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 16/16 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:19 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.84it/s</span> <span style=\"font-style: italic\">v_num: usal valid_loss: 22644.957   </span>\n                                                                               <span style=\"font-style: italic\">train_loss: 19583.750 time_forward: </span>\n                                                                               <span style=\"font-style: italic\">0.957                               </span>\n</pre>\n",
         "text/plain": "Epoch 4/4  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 16/16 \u001b[2m0:00:19 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m0.84it/s\u001b[0m \u001b[3mv_num: usal valid_loss: 22644.957   \u001b[0m\n                                                                               \u001b[3mtrain_loss: 19583.750 time_forward: \u001b[0m\n                                                                               \u001b[3m0.957                               \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
