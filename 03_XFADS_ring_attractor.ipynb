{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KXXKQnR7c6cx",
   "metadata": {
    "id": "KXXKQnR7c6cx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "startupMode = 'dev'\n",
    "\n",
    "if startupMode == 'colab':\n",
    "    %pip install --quiet pytorch-lightning hydra-core\n",
    "    %pip install git+https://github.com/catniplab/xfads\n",
    "    !git clone https://github.com/catniplab/xfads\n",
    "    %cd xfads/examples/ring_attractor\n",
    "    config_path = \"../content/xfads/examples/ring_attractor\"\n",
    "elif startupMode == 'dev':\n",
    "    import sys\n",
    "    sys.path.append('../..') # add path for xfads root\n",
    "\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    config_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ALTbmnGoemgT",
   "metadata": {
    "id": "ALTbmnGoemgT"
   },
   "source": [
    "# Nonlinear State Space Modeling via XFADS - simulated ring attractor\n",
    "\n",
    "Dowling, M., Zhao, Y., & Park, I. M. (2024). eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling. The Thirty-Eighth Annual Conference on Neural Information Processing Systems. NeurIPS. https://openreview.net/forum?id=Ln8ogihZ2S\n",
    "\n",
    "XFADS is our favorite variational autoencoder for nonlinear state space modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cba071f9d2e2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:31:26.965868Z",
     "start_time": "2025-07-02T17:31:24.009001Z"
    },
    "id": "46cba071f9d2e2f7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import xfads.utils as utils\n",
    "import xfads.plot_utils as plot_utils\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics\n",
    "from xfads.ssm_modules.likelihoods import GaussianLikelihood\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.smoothers.lightning_trainers import LightningNonlinearSSM\n",
    "from xfads.smoothers.nonlinear_smoother import NonlinearFilterSmallL, LowRankNonlinearStateSpaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29d5d4f2a7536",
   "metadata": {
    "id": "2ee29d5d4f2a7536"
   },
   "source": [
    "## ‚öôÔ∏è 2. Initialize Configuration\n",
    "\n",
    "We use Hydra to load experiment configs and set up deterministic behavior for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c27e664155363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:31:29.253455Z",
     "start_time": "2025-07-02T17:31:29.098163Z"
    },
    "id": "2d7c27e664155363",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "\n",
    "cfg_dict = {\n",
    "    # --- graphical model --- #\n",
    "    'n_latents': 2,\n",
    "    'n_latents_read': 2,\n",
    "    'rank_local': 2,\n",
    "    'rank_backward': 2,\n",
    "    'n_hidden_dynamics': 64,\n",
    "\n",
    "    # --- inference network --- #\n",
    "    'n_samples': 5,\n",
    "    'n_hidden_local': 128,\n",
    "    'n_hidden_backward': 64,\n",
    "\n",
    "    # --- hyperparameters --- #\n",
    "    'use_cd': False,\n",
    "    'p_mask_a': 0.8,\n",
    "    'p_mask_b': 0.0,\n",
    "    'p_mask_apb': 0.0,\n",
    "    'p_mask_y_in': 0.0,\n",
    "    'p_local_dropout': 0.4,\n",
    "    'p_backward_dropout': 0.0,\n",
    "    'lr_gamma_decay': 0.99,\n",
    "\n",
    "    # --- training --- #\n",
    "    'device': 'cpu',\n",
    "    'data_device': 'cpu',\n",
    "    'lr': 1e-3,\n",
    "    'n_epochs': 150,\n",
    "    'batch_sz': 128,\n",
    "\n",
    "    # --- misc --- #\n",
    "    'bin_sz': 20e-3,\n",
    "    'bin_sz_ms': 20,\n",
    "    'seed': 1234,\n",
    "    'default_dtype': torch.float32,\n",
    "}\n",
    "\n",
    "class Cfg(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self:\n",
    "            return self[attr]\n",
    "        else:\n",
    "            raise AttributeError(f\"'Cfg' object has no attribute '{attr}'\")\n",
    "\n",
    "cfg = Cfg(cfg_dict)\n",
    "\n",
    "# Set devices and seed\n",
    "if not torch.cuda.is_available():\n",
    "    cfg.device = 'cpu'\n",
    "    cfg.data_device = 'cpu'\n",
    "\n",
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(cfg.default_dtype)\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oyjxd98x7zpy",
   "metadata": {
    "id": "oyjxd98x7zpy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "cfg.device = device\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# A quick test\n",
    "matrix_a = torch.randn(1024, 1024, device=device)\n",
    "result = torch.matmul(matrix_a, matrix_a)\n",
    "\n",
    "# cfg['n_epochs'] = 50  # reduced epochs for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166b21e3be10cb2",
   "metadata": {
    "id": "5166b21e3be10cb2"
   },
   "source": [
    "## üìà 3. Simulate Data\n",
    "\n",
    "We generate data from a 2D ring attractor latent dynamic system, projecting into 100-dimensional observations using a fixed linear readout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb244a2edaa6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:31:31.453353Z",
     "start_time": "2025-07-02T17:31:31.049992Z"
    },
    "id": "ffb244a2edaa6d8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_trials = 3000\n",
    "n_neurons = 100\n",
    "n_time_bins = 75\n",
    "\n",
    "mean_fn = utils.RingAttractorDynamics(bin_sz=1e-1, w=0.0)\n",
    "C = utils.FanInLinear(cfg.n_latents, n_neurons, device=cfg.device).requires_grad_(False)\n",
    "\n",
    "Q_diag = 5e-3 * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1.0 * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "R_diag = 1e-1 * torch.ones(n_neurons, device=cfg.device)\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "\n",
    "z = utils.sample_gauss_z(mean_fn, Q_diag, m_0, Q_0_diag, n_trials, n_time_bins)\n",
    "y = C(z) + torch.sqrt(R_diag) * torch.randn((n_trials, n_time_bins, n_neurons), device=cfg.device)\n",
    "y = y.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807079c3ba83cee",
   "metadata": {
    "id": "8807079c3ba83cee"
   },
   "source": [
    "## üìà 4. Visualize Latent Trajectories\n",
    "\n",
    "Let's look at some sample trajectories from the 2D latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d352ca0ed99d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:14.577538Z",
     "start_time": "2025-07-02T19:44:12.295093Z"
    },
    "id": "861d352ca0ed99d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 6))\n",
    "for i in range(40):\n",
    "    axs.plot(z[i, :, 0].cpu(), z[i, :, 1].cpu(), alpha=0.6, linewidth=0.5)\n",
    "\n",
    "plot_utils.plot_two_d_vector_field(mean_fn, axs, min_xy=-2, max_xy=2)\n",
    "axs.set_title(\"Sample Latent Trajectories (2D Ring Attractor)\")\n",
    "axs.set_xlabel(\"Latent dim 1\")\n",
    "axs.set_ylabel(\"Latent dim 2\")\n",
    "axs.set_xlim(-2, 2)\n",
    "axs.set_ylim(-2, 2)\n",
    "axs.set_box_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfaaf7d41583a4",
   "metadata": {
    "id": "f9cfaaf7d41583a4"
   },
   "source": [
    "##  5. Prepare Train/Validation Dataloaders\n",
    "\n",
    "Split the simulated data into training and validation sets and prepare PyTorch dataloaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0486dd107fdfad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:27.362064Z",
     "start_time": "2025-07-02T17:34:27.358468Z"
    },
    "id": "3f0486dd107fdfad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    elem = batch[0]\n",
    "    if isinstance(elem, (tuple, list)):\n",
    "        return tuple(torch.stack([b[i] for b in batch]).to(cfg.device) for i in range(len(elem)))\n",
    "    else:\n",
    "        return torch.stack(batch).to(cfg.device)\n",
    "\n",
    "y_train, z_train = y[:2*n_trials//3], z[:2*n_trials//3]\n",
    "y_valid, z_valid = y[2*n_trials//3:], z[2*n_trials//3:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(y_train), batch_size=cfg.batch_sz, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(y_valid), batch_size=cfg.batch_sz, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a019425d36406e",
   "metadata": {
    "id": "e0a019425d36406e"
   },
   "source": [
    "## üß± 6. Define Model Components\n",
    "\n",
    "We define the following:\n",
    "- A Gaussian likelihood with a fixed observation noise\n",
    "- A nonlinear Gaussian dynamics module\n",
    "- A prior over the initial condition\n",
    "- Local and backward encoders for amortized inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a0d03984446ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:28.493744Z",
     "start_time": "2025-07-02T17:34:28.155205Z"
    },
    "id": "2e9a0d03984446ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Likelihood\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, C)\n",
    "likelihood_pdf = GaussianLikelihood(readout_fn, n_neurons, R_diag, device=cfg.device, fix_R=True)\n",
    "\n",
    "# Dynamics\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)\n",
    "\n",
    "# Initial condition\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)\n",
    "\n",
    "# Encoders\n",
    "backward_encoder = BackwardEncoderLRMvn(\n",
    "    cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "    rank_local=cfg.rank_local, rank_backward=cfg.rank_backward, device=cfg.device\n",
    ")\n",
    "local_encoder = LocalEncoderLRMvn(\n",
    "    cfg.n_latents, n_neurons, cfg.n_hidden_local, cfg.n_latents,\n",
    "    rank=cfg.rank_local, device=cfg.device, dropout=cfg.p_local_dropout\n",
    ")\n",
    "\n",
    "# Nonlinear filtering\n",
    "nl_filter = NonlinearFilterSmallL(dynamics_mod, initial_condition_pdf, device=cfg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40405b7f1966f90a",
   "metadata": {
    "id": "40405b7f1966f90a"
   },
   "source": [
    "## üß† 7. Assemble the State Space Model\n",
    "\n",
    "We combine dynamics, likelihood, encoders, and filtering into a complete latent variable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449ba34d5b2aaa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:29.772353Z",
     "start_time": "2025-07-02T17:34:29.769558Z"
    },
    "id": "d449ba34d5b2aaa2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm = LowRankNonlinearStateSpaceModel(\n",
    "    dynamics_mod, likelihood_pdf, initial_condition_pdf,\n",
    "    backward_encoder, local_encoder, nl_filter, device=cfg.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726c69556e898d1",
   "metadata": {
    "id": "d726c69556e898d1"
   },
   "source": [
    "## üîÅ 8. Train the Model Using PyTorch Lightning\n",
    "\n",
    "We use `LightningNonlinearSSM` for training. Logging and checkpointing are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkmlKUzQmbTz",
   "metadata": {
    "id": "mkmlKUzQmbTz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Timer\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529df5e92cc355f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T17:34:31.024563Z",
     "start_time": "2025-07-02T17:34:31.005135Z"
    },
    "id": "529df5e92cc355f9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_from_scratch = False\n",
    "\n",
    "if train_from_scratch:\n",
    "    seq_vae = LightningNonlinearSSM(ssm, cfg)\n",
    "\n",
    "    csv_logger = CSVLogger('logs/', name=f'r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='noncausal')\n",
    "    ckpt_callback = ModelCheckpoint(\n",
    "        save_top_k=3, monitor='valid_loss', mode='min',\n",
    "        dirpath='ckpts/', filename='{epoch:0}_{valid_loss:.2f}'\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg.n_epochs,\n",
    "        gradient_clip_val=1.0,\n",
    "        default_root_dir='lightning/',\n",
    "        callbacks=[ckpt_callback,timer],\n",
    "        accelerator=cfg.device,  # disable autodetection (no MPS support!)\n",
    "        logger=csv_logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=seq_vae, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "    torch.save(ckpt_callback.best_model_path, 'ckpts/best_model_path.pt')\n",
    "\n",
    "else:\n",
    "    seq_vae = LightningNonlinearSSM.load_from_checkpoint('ckpts/example_model.ckpt', ssm=ssm, cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aXzym_zRdSzV",
   "metadata": {
    "id": "aXzym_zRdSzV"
   },
   "outputs": [],
   "source": [
    "print(timer.time_elapsed(\"train\"))  # total training time\n",
    "print(timer.time_elapsed(\"validate\"))  # validation time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7d9f2fd34e1af",
   "metadata": {
    "id": "1bb7d9f2fd34e1af"
   },
   "source": [
    "## ‚úÖ Done!\n",
    "\n",
    "The model is now trained. You can proceed with:\n",
    "- Plotting smoothed trajectories.\n",
    "- Visualizing uncertainty.\n",
    "- Comparing inferred vs. ground truth latents (since this was a synthetic dataset).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef34e7cb93bc02",
   "metadata": {
    "id": "89ef34e7cb93bc02"
   },
   "source": [
    "## üåÄ 9. Visualize Learned Dynamics and Simulated Trajectories\n",
    "\n",
    "Now that training is complete, we can explore what the model has learned.  \n",
    "This section:\n",
    "- Seeds the latent space with initial conditions.\n",
    "- Rolls out the learned dynamics forward in time.\n",
    "- Overlays those trajectories onto the learned dynamics vector field.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7254c298d909a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:02.851607Z",
     "start_time": "2025-07-02T19:45:02.821724Z"
    },
    "id": "19d7254c298d909a"
   },
   "outputs": [],
   "source": [
    "# Define number of rollout samples and rollout length\n",
    "n_ex_samples = 1\n",
    "n_ex_trials = 50\n",
    "n_ex_time_bins = 50\n",
    "\n",
    "# Sample initial latent states (z_0): a mix of small and large amplitude noise\n",
    "z_0 = torch.zeros((n_ex_samples, n_ex_trials, 2))\n",
    "z_0[:, ::2] = 0.2 * torch.randn_like(z_0[:, ::2])   # small amplitude for even-indexed trials\n",
    "z_0[:, 1::2] = 2.0 * torch.randn_like(z_0[:, 1::2])  # large amplitude for odd-indexed trials\n",
    "\n",
    "# Predict forward using the learned dynamics (no encoder or data used here)\n",
    "z_prd = seq_vae.ssm.predict_forward(z_0, n_ex_time_bins).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d07535c3a411d",
   "metadata": {
    "id": "996d07535c3a411d"
   },
   "source": [
    "### üß≠ Plot: Learned Dynamics Vector Field + Predicted Latent Trajectories\n",
    "\n",
    "The vector field shows the learned mean dynamics function.\n",
    "Each curve shows a rollout of the model's latent trajectory starting from a different `z_0`.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec996ab8b81f07bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:05.730298Z",
     "start_time": "2025-07-02T19:45:04.900025Z"
    },
    "id": "ec996ab8b81f07bd"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(6, 6))\n",
    "axs.set_box_aspect(1.0)\n",
    "axs.set_xlim(-2.0, 2.0)\n",
    "axs.set_ylim(-2.0, 2.0)\n",
    "axs.set_title(\"Learned Dynamics and Autonomous Latent Trajectories\")\n",
    "\n",
    "# Plot learned vector field over the 2D latent space\n",
    "plot_utils.plot_two_d_vector_field(\n",
    "    seq_vae.ssm.dynamics_mod.mean_fn,\n",
    "    axs,\n",
    "    min_xy=-2,\n",
    "    max_xy=2,\n",
    ")\n",
    "\n",
    "# Overlay predicted trajectories\n",
    "for i in range(50):  # plot 50 of the 50\n",
    "    axs.plot(z_prd[0, i, :, 0].cpu(), z_prd[0, i, :, 1].cpu(), lw=0.5, alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb212b3aeaa9f77",
   "metadata": {
    "id": "aeb212b3aeaa9f77"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
