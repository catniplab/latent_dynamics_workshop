{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdgBJgZEwQS-"
   },
   "source": [
    "# **eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/catniplab/latent_dynamics_workshop/blob/main/04_xfads_mc_maze_demo.ipynb)\n",
    "\n",
    "A structured variational autoencoding framework for nonlinear state-space models capable of capturing dense covariance structures that are important for learning dynamical systems with predictive capabilities. Furthermore, when applied to neural recordings, our approach is able to learn a dynamical system capable of forecasting population spiking and behavioral correlates from a small portion of a single trial.\n",
    "\n",
    "To infer latent trajectories, XFADS leverages some quintessential properties of the exponential family distributions.\n",
    "\n",
    "This is a walk-through of some of the core functions of XFADS applied to spiking neural recordings. We will be building and training a state-space model of the [MC_Maze](https://neurallatents.github.io/datasets.html) dataset as a benchmark, which is a delayed center-out reaching task with obstructing barriers forming a maze, resulting in a variety of straight and curved reaches.\n",
    "\n",
    "With adequate configs and suitable choices of distributions for the SSM modules (as we will see below), you can fit XFADS on different spans of neural data.<br>\n",
    "\n",
    "[Dowling, Zhao, Park. 2024](https://arxiv.org/abs/2403.01371)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGXauB2Q1SGv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    _in_colab = True\n",
    "except:\n",
    "    _in_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWuhMh-rwfaV"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Create a `build-system` for the `xfads` package from the `pyproject.toml`\n",
    "\n",
    "(If you are local, make sure to run this command in the terminal after cd'íng to the project/ workshop main directory and activating the conda environment)\n",
    "\n",
    "`pip install -e xfads/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yru2qcStTux",
    "outputId": "a5ad988d-295b-4d04-8fd0-b42c853ecd3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if _in_colab:\n",
    "    !git clone --recurse-submodules https://github.com/catniplab/latent_dynamics_workshop.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98UVtFZVuQ18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if _in_colab:\n",
    "    sys.path.append(os.path.join(cwd, \"latent_dynamics_workshop\"))\n",
    "    sys.path.append(os.path.join(cwd, \"latent_dynamics_workshop/xfads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpzrEF65s40C",
    "outputId": "3168e51a-5556-47bd-b9f0-77fb93b98fb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if _in_colab:\n",
    "    !pip install -e latent_dynamics_workshop/xfads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2FW2rSzMgbf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FD1gks9539h"
   },
   "source": [
    "# Model and training parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8AFfW4C0QDA",
    "outputId": "2543cb04-824b-40f2-ade3-1038d0d9df8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "cfg = {\n",
    "    # --- graphical model --- #\n",
    "    'n_latents': 40,\n",
    "    'n_latents_read': 35,\n",
    "\n",
    "    'rank_local': 15,\n",
    "    'rank_backward': 5,\n",
    "\n",
    "    'n_hidden_dynamics': 128,\n",
    "\n",
    "    # --- inference network --- #\n",
    "    'n_samples': 25,\n",
    "    'n_hidden_local': 256,\n",
    "    'n_hidden_backward': 128,\n",
    "\n",
    "    # --- hyperparameters --- #\n",
    "    'use_cd': False,\n",
    "    'p_mask_a': 0.0,\n",
    "    'p_mask_b': 0.0,\n",
    "    'p_mask_apb': 0.0,\n",
    "    'p_mask_y_in': 0.0,\n",
    "    'p_local_dropout': 0.4,\n",
    "    'p_backward_dropout': 0.0,\n",
    "\n",
    "    # --- training --- #\n",
    "    'device': 'cpu',\n",
    "    'data_device': 'cpu',\n",
    "\n",
    "    'lr': 1e-3,\n",
    "    'lr_gamma_decay': 0.997,\n",
    "    'n_epochs': 3,\n",
    "    'batch_sz': 128,\n",
    "\n",
    "    # --- misc --- #\n",
    "    'bin_sz': 20e-3,\n",
    "    'bin_sz_ms': 20,\n",
    "\n",
    "    'seed': 1234,\n",
    "    'default_dtype': torch.float32,\n",
    "}\n",
    "\n",
    "class Cfg(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self:\n",
    "            return self[attr]\n",
    "        else:\n",
    "            raise AttributeError(f\"'DictAsAttributes' object has no attribute '{attr}'\")\n",
    "\n",
    "cfg = Cfg(cfg)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    cfg.device = 'cpu'\n",
    "    cfg.data_device = 'cpu'\n",
    "\n",
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CnUdSdw3oh1"
   },
   "source": [
    "# Load the data\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/catniplab/latent_dynamics_workshop/blob/main/img/maze.png?raw=1\"/>\n",
    "</p>\n",
    "\n",
    "**Neural activity:**\n",
    "- Binned at 20 ms\n",
    "- Covers 45 bins per trial\n",
    "- Time window: -240 ms to +660 ms relative to movement onset\n",
    "\n",
    "**Kinematics (hand velocity):**\n",
    "- binned at 20 ms\n",
    "- Covers 35 bins per trial\n",
    "- Time window: -40 ms to +660 ms relative to movement onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg2EWDHA0xz_",
    "outputId": "39e478e5-1f38-4ace-f097-63703c267851",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_splits_path = './xfads/examples/monkey_reaching/data' if not _in_colab else 'latent_dynamics_workshop/xfads/examples/monkey_reaching/data'\n",
    "\n",
    "train_data = torch.load(data_splits_path + f'/data_train_{cfg.bin_sz_ms}ms.pt')\n",
    "valid_data = torch.load(data_splits_path + f'/data_valid_{cfg.bin_sz_ms}ms.pt')\n",
    "test_data = torch.load(data_splits_path + f'/data_test_{cfg.bin_sz_ms}ms.pt')\n",
    "\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKDW3TCv3xY2",
    "outputId": "b728c5d7-6c66-44c9-ca0b-65a053d70cdd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_valid_obs = valid_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_valid = valid_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "print(y_train_obs.shape) # trials x time bins x neurons\n",
    "print(vel_valid.shape) # trials x time bins x vx, vy\n",
    "print(vel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zokgW1Ips40D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_single_reaches(reaches, n_trials_to_plot):\n",
    "    trial_plt_dx = torch.randperm(reaches.shape[0])[:n_trials_to_plot]\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.suptitle('hand reaches')\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    ax.axis('off')\n",
    "\n",
    "    for n in trial_plt_dx:\n",
    "        traj = torch.cumsum(reaches[n], dim=0)\n",
    "        reach_angle = torch.atan2(traj[-1, 0], traj[-1, 1])\n",
    "        reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "        \n",
    "        ax.plot(traj[:, 0], traj[:, 1], linewidth=1.0, alpha=0.8, color=reach_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "6L9jxfBZs40D",
    "outputId": "105494be-913f-4917-cb6c-65fa32e64b51",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_single_reaches(vel_train.cpu(), n_trials_to_plot=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkjgIzeEQHZI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "move_onset_bin = 12\n",
    "\n",
    "# at t=bin_prd_start start forecast\n",
    "bin_prd_start = 10\n",
    "\n",
    "_, n_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_bins_prd = n_bins - bin_prd_start\n",
    "\n",
    "n_bins_enc = train_data['n_time_bins_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "ci7ytE69s40E",
    "outputId": "34f7ea73-bf64-4bb7-b386-23ff55ad288b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spikes_and_behavior(spikes, velocity, binsize, trials_inds, event_bin):\n",
    "    n_trials = len(trials_inds)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=n_trials, figsize=(4 * n_trials, 6), sharex=False, sharey='row')\n",
    "    if n_trials == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for col, trial_idx in enumerate(trials_inds):\n",
    "        trial = spikes[trial_idx]\n",
    "        reach = velocity[trial_idx]\n",
    "        ax_spikes = axes[0, col]\n",
    "        ax_vel = axes[1, col]\n",
    "\n",
    "        for neuron_idx in range(trial.shape[-1]):\n",
    "            spike_times = np.where(trial[:, neuron_idx].cpu() == 1)[0]\n",
    "            ax_spikes.scatter(spike_times, [neuron_idx] * len(spike_times), s=4, color='gray', marker='|')\n",
    "\n",
    "        ax_spikes.axvline(x=event_bin, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_spikes.set_ylabel('neurons')\n",
    "        ax_spikes.set_title(f'Trial {trial_idx}\\n# spikes: {int(torch.sum(trial))}', fontsize=10)\n",
    "        ax_spikes.set_xlabel('time bins')\n",
    "\n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, reach[:, 0], color='navy', label='vel x')\n",
    "        ax_vel.plot(time_axis, reach[:, 1], color='coral', label='vel y')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_vel.set_xlabel('time (ms)')\n",
    "        ax_vel.set_title('hand velocity', fontsize=10)\n",
    "        ax_vel.legend(fontsize=8)\n",
    "\n",
    "        if col == 0:\n",
    "            _, y_top = ax_spikes.get_ylim()\n",
    "            ax_spikes.annotate(\"movement\\nonset\", xy=(event_bin, y_top), xytext=(event_bin - 10, y_top + 3),\n",
    "                               arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                               fontsize=7, ha='center', alpha=0.8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_spikes_and_behavior(y_train_obs.cpu(), vel_train.cpu(), cfg.bin_sz_ms,\n",
    "                         torch.randperm(y_train_obs.size(0))[:4],\n",
    "                         event_bin=move_onset_bin,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D2T189rwAs-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"prepare data for torch\"\"\"\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJRyAgx_BUGc"
   },
   "source": [
    "# Building the State Space Model\n",
    "\n",
    "The basic elements of any state space model are:<br>\n",
    "- **Dynamics Model**, i.e. the stochastic differential equation that governs how the latents (state variables) evolve over time.\n",
    "- **Observations Model**, i.e. the data likelihood, given the latents, that governs how the state variables can generate corresponding observations.\n",
    "\n",
    "The modules to build up the state space model, to be learned by XFADS, are organized as Python classes, in a way allowing users to change and plug in their own classes that structure the elements of the model, i.e. the dynamics function, the likelihood density, and the inference network. The configuration depends on the problem: `dynamics_mod`, `initial_c_pdf`, `likelihood_pdf`, `local_encoder`, and `backward_encoder` can be configured as desired. We include some general classes in `ssm_modules/encoders`, `ssm_modules/likelihoods`, and `ssm_modules/dynamics` that should be sufficient for a wide range of problems.  Below is an example configuration.\n",
    "\n",
    "In each iteration of the Variational Inference, we need to optimize the parameters of the approximate posterior, which can be quite inefficient,\n",
    "\n",
    "To amortize the computational cost at inference time, we follow the technique of using a trainable NN, known as an **inference network** (a.k.a recognition model or \"encoder\") that outputs the posterior from the observed data.\n",
    "\n",
    "A possible drawback of the typical sequential VAEs is that they cannot naturally handle missing observations. To enable the amortized inference network to process missing observations in a principled way, we decompose the natural parameter update, of the approximate posterior, into two additive components (explained, and the intuition behind it, more in the next step). We use missing observations when masking time to encourage better forecasting.\n",
    "\n",
    "For a detailed building of XFADS, check the Method section of [the paper](https://arxiv.org/abs/2403.01371).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/catniplab/latent_dynamics_workshop/blob/main/img/ssm_diagram.png?raw=1\" width=1000/>\n",
    "</p><p align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYS7gATKDTHF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint\n",
    "\n",
    "import xfads.utils as utils\n",
    "import xfads.prob_utils as prob_utils\n",
    "import xfads.plot_utils as plot_utils\n",
    "\n",
    "from xfads.smoothers.nonlinear_smoother_causal import LowRankNonlinearStateSpaceModel, NonlinearFilter\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics, DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.ssm_modules.likelihoods import PoissonLikelihood\n",
    "\n",
    "from xfads.smoothers.lightning_trainers import LightningMonkeyReaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3LWqPWgoLa4"
   },
   "source": [
    "`smoothers.lightning_trainers` provides PyTorch Lightning modules for fitting state-space models to neural population activity, with support for our structured variational inference, input-driven latent dynamics, and temporally scheduled masking of observations. These modules standardize training, validation, and testing workflows, including log-likelihood computation, bits-per-spike metrics, and linear decoding of behavior from inferred firing rates or latent states.\n",
    "\n",
    "The `LightningMonkeyReaching` class is tailored for the MC Maze task, combining spiking and kinematic data from non-human primates. It supports masked training for robust inference, forward prediction from partial observations, and model selection based on R² scores from decoding hand velocity, enabling evaluation of both latent representation quality and predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLZg5XcPBTkS",
    "outputId": "03bf92ff-1fc8-47b5-f716-82e6858a5034",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"likelihood module\"\"\"\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, nn.Linear(cfg.n_latents_read, n_neurons_obs))\n",
    "likelihood_pdf = PoissonLikelihood(readout_fn, n_neurons_obs, cfg.bin_sz, device=cfg.device)\n",
    "\n",
    "\"\"\"dynamics module\"\"\"\n",
    "Q_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"initial condition\"\"\"\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"local/backward encoder\"\"\"\n",
    "backward_encoder = BackwardEncoderLRMvn(cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "                                        rank_local=cfg.rank_local, rank_backward=cfg.rank_backward,\n",
    "                                        device=cfg.device)\n",
    "local_encoder = LocalEncoderLRMvn(cfg.n_latents, n_neurons_obs, cfg.n_hidden_local, cfg.n_latents,rank=cfg.rank_local,\n",
    "                                  device=cfg.device, dropout=cfg.p_local_dropout)\n",
    "\n",
    "\"\"\"nonlinear filter\"\"\"\n",
    "nl_filter = NonlinearFilter(dynamics_mod, initial_condition_pdf, device=cfg.device)\n",
    "\n",
    "\"\"\"sequential vae\"\"\"\n",
    "ssm = LowRankNonlinearStateSpaceModel(dynamics_mod, likelihood_pdf, initial_condition_pdf, backward_encoder,\n",
    "                                      local_encoder, nl_filter, device=cfg.device)\n",
    "\n",
    "seq_vae = LightningMonkeyReaching(ssm, cfg, n_bins_enc, bin_prd_start)\n",
    "seq_vae.ssm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "23999d073ec34bf68f28c909df6b166a",
      "32df54d200534736aa097c81eea74e56"
     ]
    },
    "id": "fUdGN3UVGOz6",
    "outputId": "da49b3ae-3103-4da4-9063-66ef9690b948",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_from_scratch = True\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if _in_colab:\n",
    "    log_path = 'latent_dynamics_workshop/logs/mc_maze'\n",
    "    ckpts_path = 'latent_dynamics_workshop/ckpts/mc_maze'\n",
    "else:\n",
    "    log_path = './logs/mc_maze'\n",
    "    ckpts_path = './ckpts/mc_maze'\n",
    "\n",
    "if train_from_scratch:\n",
    "    csv_logger = CSVLogger(log_path,\n",
    "                           name=f'sd_{cfg.seed}_r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}_mask_{cfg.p_mask_a}',\n",
    "                           version='smoother_causal')\n",
    "    ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='r2_valid_enc', mode='max',\n",
    "                                    dirpath=f'{ckpts_path}/', save_last=True,\n",
    "                                    filename='{epoch:0}_{valid_loss:0.2f}_{r2_valid_enc:0.2f}_{r2_valid_prd:0.2f}_{valid_bps_enc:0.2f}')\n",
    "    trainer_kwargs = dict(\n",
    "        max_epochs=cfg.n_epochs,\n",
    "        gradient_clip_val=1.0,\n",
    "        default_root_dir=\"lightning/\",\n",
    "        callbacks=[RichProgressBar(), ckpt_callback],\n",
    "        logger=csv_logger,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    if cfg.device == 'cuda':\n",
    "        trainer_kwargs.update(accelerator=\"gpu\", devices=1)\n",
    "    if cfg.device == 'cpu':\n",
    "        trainer_kwargs.update(accelerator=\"cpu\")\n",
    "\n",
    "    trainer = lightning.Trainer(**trainer_kwargs)\n",
    "\n",
    "    seq_vae.train()\n",
    "    trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "\n",
    "    best_model_path_saved = ckpt_callback.best_model_path\n",
    "    torch.save(best_model_path_saved, f'{ckpts_path}/best_model_path.pt')\n",
    "    \n",
    "else:\n",
    "    \"\"\"loading the trained model\"\"\"\n",
    "    best_model_path = f'{ckpts_path}/epoch=827_valid_loss=1415.56_r2_valid_enc=0.89_r2_valid_bhv=0.00_valid_bps_enc=0.42.ckpt'\n",
    "    seq_vae = LightningMonkeyReaching.load_from_checkpoint(best_model_path, ssm=ssm, cfg=cfg,\n",
    "                                                            n_time_bins_enc=n_bins_enc, n_time_bins_bhv=bin_prd_start,\n",
    "                                                            strict=False)\n",
    "    seq_vae.ssm = seq_vae.ssm.to(cfg.device)\n",
    "    \n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5YVc6cPItcI"
   },
   "source": [
    "# Inference network\n",
    "\n",
    "Drawing inspiration from conjugate Bayesian Inference (where the prior distribution and the likelihood function are chosen such that the posterior distribution belongs to the same family as the prior distribution), the **natural parameters of the posterior** can be expressed as a sum-separable combination of the **natural parameters of the prior** and a **data-dependent term**.\n",
    "\\begin{matrix}\n",
    "\\large\\lambda_{\\phi}(z_{t-1}, y_{t:T}) = \\lambda_{\\theta}(z_{t-1}) + \\tilde\\lambda_{\\theta}(y_{t:T})\n",
    "\\end{matrix}\n",
    "\n",
    "This separation allows the approximate posterior to hold even when there are missing observations (e.g. a circuit glitch, masking, lost signal, etc). In such case, $\\tilde\\lambda_{\\theta}(y_{t})$, which we call, **the pseudo opservation $\\tilde{y}_{t}$**, can be set to zero.\n",
    "\n",
    "a **local encoder**, for current observation, and ii) a **backward encoder**, for future observations. In addition, the separation of local and backward encoders can reduce the complexity of the backward encoder for *L < N* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eochah1Js40E"
   },
   "source": [
    "## Smoothing\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/catniplab/latent_dynamics_workshop/blob/main/img/smoothing.png?raw=1\" width=600/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfFTrEdsJrLK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, z_s_train, stats = seq_vae.ssm(y_train_obs, cfg.n_samples)\n",
    "    loss, z_s_valid, stats = seq_vae.ssm(y_valid_obs, cfg.n_samples)\n",
    "    loss, z_s_test, stats = seq_vae.ssm(y_test_obs, cfg.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YcmEVU7Ph4o"
   },
   "source": [
    "## Filtering\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/catniplab/latent_dynamics_workshop/blob/main/img/filtering.png?raw=1\" width=600/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p23hyeEDJlbj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, z_f_train, stats = seq_vae.ssm.forward_filter(y_train_obs, cfg.n_samples)\n",
    "    loss, z_f_valid, stats = seq_vae.ssm.forward_filter(y_valid_obs, cfg.n_samples)\n",
    "    loss, z_f_test, stats = seq_vae.ssm.forward_filter(y_test_obs, cfg.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "\n",
    "The `seq_vae.ssm.predict_forward()` function simulates the dynamics of the latent states forward in time, starting from an initial filtered latent state $z_{t-1}$ from the filtering posterior.\\\n",
    "It implements a generative forward model that predicts future latent states, for a number of future time bins = `n_bins_prd`, using:\n",
    "\n",
    "- A learned dynamics function `dynamics_mod.mean_fn()`\n",
    "- Added process noise drawn from a Gaussian distribution\n",
    "\n",
    "The prediction step in the latent dynamics follows this form:\n",
    "\n",
    "$$\n",
    "z_t = \\mu(z_{t-1}) + Q^{1/2} \\cdot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $z_t$ is the predicted latent state at the current time bin $t$\n",
    "- $\\mu(z_{t-1})$ is the output of the learned transition function `mean_fn`\n",
    "- $Q^{1/2}$ is the element-wise square root of the process noise covariance (i.e., standard deviation)\n",
    "- $\\epsilon$ is Gaussian noise drawn from a standard normal distribution\n",
    "\n",
    "This equation iterates from an initial latent state, which is typically the last observed latent before prediction begins. Each predicted state depends on the previous one, forming an open-loop generative rollout of latent dynamics, i.e.  without using ground-truth inputs at each time step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glYgnM1oJld9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_f_p= lambda f, p: torch.cat([f, p], dim=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_p_train = cat_f_p(z_f_train[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_train[:, :, bin_prd_start], n_bins_prd))\n",
    "    z_p_valid = cat_f_p(z_f_valid[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_valid[:, :, bin_prd_start], n_bins_prd))\n",
    "    z_p_test = cat_f_p(z_f_test[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_test[:, :, bin_prd_start], n_bins_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rghyjRdNYrW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"colors\"\"\"\n",
    "blues = cm.get_cmap(\"winter\", z_s_test.shape[0])\n",
    "reds = cm.get_cmap(\"summer\", z_s_test.shape[0])\n",
    "springs = cm.get_cmap(\"spring\", z_s_test.shape[0])\n",
    "\n",
    "trial_list = [28, 202, 8, 285]\n",
    "color_map_list = [blues, reds, springs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "Etgfwho-NYxs",
    "outputId": "e2d8d4e3-7a98-4620-aa07-e2a29228bd2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"smoothed latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('smoothed\\n')\n",
    "    plot_utils.plot_z_samples(fig, axs, z_s_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    axs[0].lines[-1].set_label('movement\\nonset')\n",
    "    axs[0].legend(bbox_to_anchor=(0.125, 0.96), fontsize=8, frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "sjrWtto-NY1-",
    "outputId": "00f22889-08f4-4253-fe3a-5d1b88362962",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"filtered latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('filtered')\n",
    "    plot_utils.plot_z_samples(fig, axs, z_f_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "jch1TQxoJlgO",
    "outputId": "50ddc7fa-4a53-45bf-d756-21c58a4c9066",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"forecasted latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('forecasted')\n",
    "    [axs[i].axvline(bin_prd_start, linestyle='--', color='red') for i in range(len(trial_list))]\n",
    "    plot_utils.plot_z_samples(fig, axs, z_p_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    _, y_upper_limit = axs[0].get_ylim()\n",
    "    axs[0].annotate(f\"prediction\\nstarts\",\n",
    "                      xy=(bin_prd_start, y_upper_limit),\n",
    "                      xytext=(bin_prd_start - (n_bins * 0.1), (y_upper_limit * 1.2)),\n",
    "                      arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                      fontsize=7, alpha=0.8, ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "XhM_QL2ps40F",
    "outputId": "806d5657-a548-4c5a-e1c8-981289bb21f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latents_pca_3d(z, reaches):\n",
    "    z = z.mean(dim=0).cpu()\n",
    "    trials, time_bins, latents = z.shape\n",
    "    data_reshaped = z.view(-1, latents).cpu().numpy()\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    pca_result = pca.fit_transform(data_reshaped)\n",
    "    pca_result_reshaped = pca_result.reshape(trials, time_bins, 3)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.suptitle(\"single-trial latent trajectories\", fontsize=12)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for i, traj in enumerate(pca_result_reshaped):\n",
    "        pos = torch.cumsum(reaches[i], dim=0).cpu()\n",
    "        reach_angle = torch.atan2(pos[-1, 0], pos[-1, 1])\n",
    "        reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "        ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], linewidth=0.8, alpha=0.6, color=reach_color)\n",
    "        ax.scatter(traj[0, 0], traj[0, 1], traj[0, 2], color='red', marker='o', s=10, alpha=0.1, label='start' if i == 0 else \"\")\n",
    "        ax.scatter(traj[-1, 0], traj[-1, 1], traj[-1, 2], color='gray', marker='x', s=10, alpha=0.6, label='end' if i == 0 else \"\")\n",
    "\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_latents_pca_3d(z_f_test, vel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latents_pca_2d(z, vel, nc=3):\n",
    "    z = z.mean(dim=0).cpu()\n",
    "    trials, time_bins, latents = z.shape\n",
    "    \n",
    "    pca = PCA(n_components=nc)\n",
    "    pca_result = pca.fit_transform(z.view(-1, latents).cpu().numpy())\n",
    "    pca_result_reshaped = pca_result.reshape(trials, time_bins, nc)\n",
    "\n",
    "    fig, axes = plt.subplots(1, nc, figsize=(12, 4), sharex=True, sharey=True)\n",
    "    fig.suptitle(\"single-trial latent trajectories)\", fontsize=12)\n",
    "\n",
    "    for c in range(nc):\n",
    "        for i in range(trials):\n",
    "            pos = torch.cumsum(vel[i], dim=0).cpu()\n",
    "            reach_angle = torch.atan2(pos[-1, 0], pos[-1, 1])\n",
    "            reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "            axes[c].plot(range(time_bins), pca_result_reshaped[i, :, c], linewidth=0.2,  alpha=0.4, color=reach_color)\n",
    "\n",
    "        axes[c].axvline(x=move_onset_bin, color='gold', alpha=0.8, linestyle='--', linewidth=1.0)\n",
    "        if c == 0:\n",
    "            axes[c].annotate(f\"movement\\nonset\",\n",
    "                            xy=(move_onset_bin, axes[c].get_ylim()[1]),\n",
    "                            xytext=(move_onset_bin - (n_bins*0.1), (axes[c].get_ylim()[1] * 1.2)),\n",
    "                            arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                            fontsize=8, alpha=0.8, ha='center')\n",
    "            \n",
    "        axes[c].spines['top'].set_visible(False)\n",
    "        axes[c].spines['right'].set_visible(False)\n",
    "        axes[c].set_title(f'PC{c+1}')\n",
    "        axes[c].set_xlabel('time bins (size 20 ms)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_latents_pca_2d(z_f_train, vel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latent_bins_pca_3d(z, vel):\n",
    "    z = z_f_train[:, :, :vel.shape[-2], :].mean(dim=0).cpu()\n",
    "    trials, time_bins, latents = z.shape\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_result = pca.fit_transform(z.view(-1, latents).cpu().numpy())\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    fig.suptitle(\"Single bins of the latents\", fontsize=12)\n",
    "\n",
    "    pos = torch.cumsum(vel, dim=1).cpu()\n",
    "    angles = torch.repeat_interleave(torch.atan2(pos[:, -1, 0], pos[:, -1, 1]), repeats=time_bins)\n",
    "\n",
    "    ax.scatter(pca_result[:, 0], pca_result[:, 1], pca_result[:, 2],\n",
    "               s=2, alpha=0.2, c=angles, cmap='hsv')\n",
    "\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_bins_pca_3d(z_f_train, vel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latent_bins_pca_2d(z, vel, nc=3):\n",
    "    z = z_f_train[:, :, :vel.shape[-2], :].mean(dim=0).cpu()\n",
    "    trials, time_bins, latents = z.shape\n",
    "\n",
    "    pca = PCA(n_components=nc)\n",
    "    pca_result = pca.fit_transform(z.view(-1, latents).cpu().numpy())\n",
    "\n",
    "    fig, axes = plt.subplots(1, nc, figsize=(15, 4), sharex=True, sharey=True)\n",
    "    fig.suptitle(\"single bins of the latents\", fontsize=12)\n",
    "\n",
    "    pos = torch.cumsum(vel, dim=1).cpu()\n",
    "    reach_angle = torch.atan2(pos[:, -1, 0], pos[:, -1, 1])\n",
    "\n",
    "    angles = torch.repeat_interleave(torch.atan2(pos[:, -1, 0], pos[:, -1, 1]), repeats=vel_train.shape[-2])\n",
    "\n",
    "    axes[0].scatter(pca_result[:, 0], pca_result[:, 1], s=2, alpha=0.2, c=angles, cmap='hsv')\n",
    "    axes[0].set_xlabel(\"PC1\")\n",
    "    axes[0].set_ylabel(\"PC2\")\n",
    "\n",
    "    axes[1].scatter(pca_result[:, 0], pca_result[:, 2], s=2, alpha=0.2, c=angles, cmap='hsv')\n",
    "    axes[1].set_xlabel(\"PC1\")\n",
    "    axes[1].set_ylabel(\"PC3\")\n",
    "\n",
    "    axes[2].scatter(pca_result[:, 1], pca_result[:, 2], s=2, alpha=0.2, c=angles, cmap='hsv')\n",
    "    axes[2].set_xlabel(\"PC2\")\n",
    "    axes[2].set_ylabel(\"PC3\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_latent_bins_pca_2d(z_f_train, vel_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mc3Gvd25yOV"
   },
   "source": [
    "# Generate corresponding observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yVICHfB52jn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rates_train_s = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_train)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_s = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_test)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_f = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_f_test)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_p = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_p_test)).mean(dim=0)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "osDQkF3gs40F",
    "outputId": "3377ba3e-5d26-4e63-9a30-cd3016f86b9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_trials(true_rates, generated_rates, n=4, spike_threshold=0.1):\n",
    "    true_rates = true_rates.cpu() if isinstance(true_rates, torch.Tensor) else true_rates\n",
    "    generated_rates = generated_rates.cpu() if isinstance(generated_rates, torch.Tensor) else generated_rates\n",
    "\n",
    "    trials = true_rates.shape[0]\n",
    "    n = min(n, trials)\n",
    "    random_indices = np.random.choice(trials, size=n, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, n, figsize=(2.5 * n, 8), sharex=True, sharey='row')\n",
    "\n",
    "    for idx, trial_i in enumerate(random_indices):\n",
    "        spikes = true_rates[trial_i]  # shape: [T, N]\n",
    "        T, N = spikes.shape\n",
    "\n",
    "        ax_raster = axes[0, idx]\n",
    "        spike_times, neuron_ids = np.where(spikes > spike_threshold)\n",
    "        ax_raster.scatter(spike_times, neuron_ids, s=2, color='black')\n",
    "        if idx == 0:\n",
    "            ax_raster.set_ylabel(\"neuron\")\n",
    "\n",
    "        ax_gen = axes[1, idx]\n",
    "        im = ax_gen.imshow(generated_rates[trial_i].T, aspect='auto', cmap='viridis', origin='lower')\n",
    "        if idx == 0:\n",
    "            ax_gen.set_ylabel(\"neuron\")\n",
    "            ax_gen.set_xlabel(\"time bins\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([1., 0.12, 0.015, 0.33])  # [left, bottom, width, height]\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"firing rate\")\n",
    "\n",
    "    axes[0, 0].set_title(\"Observed spikes (raster)\", fontsize=12)\n",
    "    axes[1, 0].set_title(\"Generated firing rates\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_trials(y_test_obs, rates_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09ZRaX9ps40F"
   },
   "source": [
    "# Reconstructed single-neuron firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E6iIexYJs40J",
    "outputId": "22bd72c8-b71a-4b7d-c493-faf8453b6734",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neurons_to_plot = 16\n",
    "neuron_indcs = np.random.choice(range(0, y_test_obs.shape[2]), size=n_neurons_to_plot, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(int(np.sqrt(n_neurons_to_plot)), int(np.sqrt(n_neurons_to_plot)), figsize=(14, 10))\n",
    "fig.suptitle(f'Trial-averaged neurons activity\\n\\n\\n\\n')\n",
    "\n",
    "for ax, neuron in zip(axes.flat, neuron_indcs):\n",
    "\n",
    "    fr_data = torch.mean(y_test_obs[:, :, neuron], axis=0).cpu()\n",
    "    fr_model_s = torch.mean(torch.from_numpy(rates_test_s[:, :, neuron]), axis=0)\n",
    "    fr_model_p = torch.mean(torch.from_numpy(rates_test_p[:, :, neuron]), axis=0)\n",
    "\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_data, color= 'black', alpha=0.8, label='true' if neuron == neuron_indcs[-1] else '')\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_model_s, color= 'green', alpha=1.0, label='smoothed' if neuron == neuron_indcs[-1] else '')\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_model_p, color= 'coral', alpha=1.0, label='forecasted' if neuron == neuron_indcs[-1] else '')\n",
    "\n",
    "    ax.axvline(bin_prd_start * cfg.bin_sz_ms, linestyle='--', color= 'coral')\n",
    "    ax.axvline(move_onset_bin * cfg.bin_sz_ms, linestyle='--', color= 'gray')\n",
    "\n",
    "    if neuron == neuron_indcs[0]:\n",
    "      _, y_upper_limit = ax.get_ylim()\n",
    "      ax.annotate(f\"prediction\\nstarts\",\n",
    "                      xy=(bin_prd_start * cfg.bin_sz_ms, y_upper_limit),\n",
    "                      xytext=(bin_prd_start * cfg.bin_sz_ms - (n_bins * 0.3), (y_upper_limit * 1.2)),\n",
    "                      arrowprops=dict(facecolor='black', alpha=0.2, arrowstyle='->'),\n",
    "                      fontsize=7, alpha=0.8, ha='center')\n",
    "\n",
    "    ax.set_title(f'\\nneuron {neuron+1}\\n', fontsize=8)\n",
    "    ax.set_xlabel('time (ms)' if neuron == neuron_indcs[-int(np.sqrt(n_neurons_to_plot))] else '', fontsize=9)\n",
    "    ax.set_ylabel('firing rate' if neuron == neuron_indcs[0] else '', fontsize=9)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.94), ncol=1, fontsize=8)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npBXlAmOGQQy"
   },
   "source": [
    "# Decoding hand kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RZxxe1VGWpW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "ka1zFLJWks2t",
    "outputId": "7604350a-4aca-4664-990b-30b518664b3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"velocity decoder\"\"\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    clf = Ridge(alpha=0.01)\n",
    "\n",
    "    clf.fit(rates_train_s[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), vel_train.cpu().reshape(-1, 2))\n",
    "    r2 = clf.score(rates_train_s[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), vel_train.cpu().reshape(-1, 2))\n",
    "\n",
    "    pred_reshape = lambda rates, clf, original_shape: clf.predict(rates[:, :n_bins_enc, :].reshape(-1, n_neurons_obs)).reshape(list(original_shape)[:-1] + [2])\n",
    "    calc_r2 = lambda rates, clf, true_velocity: clf.score(rates[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), true_velocity.cpu().reshape(-1, 2))\n",
    "\n",
    "    r2_test_s = calc_r2(rates_test_s, clf, vel_test)\n",
    "    r2_test_f = calc_r2(rates_test_f, clf, vel_test)\n",
    "    r2_test_p = calc_r2(rates_test_p, clf, vel_test)\n",
    "\n",
    "    vel_hat_test_s = pred_reshape(rates_test_s, clf, vel_test.shape)\n",
    "    vel_hat_test_f = pred_reshape(rates_test_f, clf, vel_test.shape)\n",
    "    vel_hat_test_p = pred_reshape(rates_test_p, clf, vel_test.shape)\n",
    "\n",
    "n_trials_test = vel_test.shape[0]\n",
    "n_trials_plot = 35\n",
    "\n",
    "vel_to_pos = lambda v: torch.cumsum(torch.tensor(v).clone().detach().to('cpu'), dim=1)\n",
    "\n",
    "pos_test = vel_to_pos(vel_test.cpu())\n",
    "trial_plt_dx = torch.randperm(n_trials_test)[:n_trials_plot]\n",
    "reach_angle = torch.atan2(pos_test[:, -1, 0], pos_test[:, -1, 1])\n",
    "reach_colors = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "\n",
    "pos_test_hat_s = vel_to_pos(vel_hat_test_s)\n",
    "pos_test_hat_f = vel_to_pos(vel_hat_test_f)\n",
    "pos_test_hat_p = vel_to_pos(vel_hat_test_p)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "    plot_utils.plot_reaching(axs[0], pos_test[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[1], pos_test_hat_s[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[2], pos_test_hat_f[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[3], pos_test_hat_p[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "\n",
    "    axs[0].set_title('true')\n",
    "    axs[1].set_title(f'smoothed, r2:{r2_test_s:.3f}')\n",
    "    axs[2].set_title(f'filtered, r2:{r2_test_f:.3f}')\n",
    "    axs[3].set_title(f'predicted, r2:{r2_test_p:.3f}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "ENliyMtWs40K",
    "outputId": "e4d3e159-f601-4636-ac67-3da2788f2d30",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spikes_and_decoded_behavior(spikes, velocity, velocity_hat, binsize, trials_inds, event_bin):\n",
    "    n_trials = len(trials_inds)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=n_trials, figsize=(4 * n_trials, 6), sharex=False, sharey='row')\n",
    "    if n_trials == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for col, trial_idx in enumerate(trials_inds):\n",
    "        trial = spikes[trial_idx]\n",
    "        reach = velocity[trial_idx]\n",
    "        decoded_reach = velocity_hat[trial_idx]\n",
    "        ax_spikes = axes[0, col]\n",
    "        ax_vel = axes[1, col]\n",
    "\n",
    "        for neuron_idx in range(trial.shape[-1]):\n",
    "            spike_times = np.where(trial[:, neuron_idx].cpu() == 1)[0]\n",
    "            ax_spikes.scatter(spike_times, [neuron_idx] * len(spike_times), s=4, color='gray', marker='|')\n",
    "\n",
    "        ax_spikes.axvline(x=event_bin, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_spikes.set_ylabel('neurons')\n",
    "        ax_spikes.set_title(f'\\nTrial {trial_idx}\\n# spikes: {int(torch.sum(trial))}', fontsize=10)\n",
    "        ax_spikes.set_xlabel('time bins')\n",
    "        \n",
    "        # True reaches\n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, reach[:, 0], color='navy', linewidth=1.0, label='true vel x' if col == 0 else '')\n",
    "        ax_vel.plot(time_axis, reach[:, 1], color='coral', linewidth=1.0, label='true vel y' if col == 0 else '')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', linewidth=1.0, color='purple', alpha=0.4)\n",
    "        ax_vel.set_xlabel('time (ms)')\n",
    "        ax_vel.set_title('\\nhand velocity', fontsize=10)\n",
    "        \n",
    "        # Decoded reaches\n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, decoded_reach[:, 0], linestyle='--', linewidth=1.0, color='navy', label='decoded vel x' if col == 0 else '')\n",
    "        ax_vel.plot(time_axis, decoded_reach[:, 1], linestyle='--', linewidth=1.0, color='coral', label='decoded vel y' if col == 0 else '')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', linewidth=1.0, color='purple', alpha=0.4)\n",
    "\n",
    "        if col == 0:\n",
    "            _, y_top = ax_spikes.get_ylim()\n",
    "            ax_spikes.annotate(\"movement\\nonset\", xy=(event_bin, y_top), xytext=(event_bin - 10, y_top + 3),\n",
    "                               arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                               fontsize=7, ha='center', alpha=0.8)\n",
    "\n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=2, fontsize=10, frameon=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_spikes_and_decoded_behavior(y_test_obs.cpu(), vel_test.cpu(), vel_hat_test_s, cfg.bin_sz_ms,\n",
    "                                 torch.randperm(y_test_obs.size(0))[:4],\n",
    "                                 event_bin=move_onset_bin,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Ea1D2PwnSNSe",
    "outputId": "482560ba-35ad-4d0c-e446-164a6581cb6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    r2_k_step = []\n",
    "    for k in range(n_bins):\n",
    "\n",
    "        z_prd_test = utils.propagate_latent_k_steps(z_f_test[:, :, k], dynamics_mod, n_bins - (k + 1))\n",
    "        z_prd_test = torch.concat([z_f_test[:, :, :k], z_prd_test], dim=2)\n",
    "\n",
    "        rates_prd_test = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_prd_test)).mean(dim=0).cpu().detach().numpy()\n",
    "        r2_prd = calc_r2(rates_prd_test, clf, vel_test)\n",
    "        r2_k_step.append(r2_prd)\n",
    "\n",
    "plt.axvline(move_onset_bin, linestyle='--')\n",
    "plt.annotate(f\"movement\\nonset\",\n",
    "             xy=(move_onset_bin, y_upper_limit),\n",
    "             xytext=(move_onset_bin + (n_bins * 0.15), (y_upper_limit * 1.2)),\n",
    "             arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "             fontsize=7, alpha=0.8, ha='center')\n",
    "\n",
    "plt.plot(r2_k_step)\n",
    "plt.axhline(r2_test_s, color='green', label='smoothed')\n",
    "plt.axhline(r2_test_f, color='orange', label='filtered')\n",
    "plt.xlabel('bin prd start')\n",
    "plt.ylabel('r2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlV-9xtihHrb"
   },
   "source": [
    "Evaluating how well future hand velocity can be decoded from the model's predictions when starting the prediction from different points in the trial (k). This analysis assesses how the model's ability to forecast the remaining hand movement changes depending on how much of the initial trial data it has observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "CSNArfrHs40K",
    "outputId": "545fefc0-8525-461a-e38d-fba6dc1d0abf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_vs_r2_plot(z_train, z_test, vel_train, vel_test, max_pcs=30, alpha=0.01):\n",
    "    def flatten(x):\n",
    "        return x.reshape(-1, x.shape[2]).detach().cpu().numpy()\n",
    "\n",
    "    def flatten_vel(v):\n",
    "        return v.reshape(-1, 2).detach().cpu().numpy()\n",
    "\n",
    "    X_train = flatten(z_train)\n",
    "    X_test = flatten(z_test)\n",
    "    y_train = flatten_vel(vel_train)\n",
    "    y_test = flatten_vel(vel_test)\n",
    "\n",
    "    r2_scores = []\n",
    "\n",
    "    for k in range(1, max_pcs + 1):\n",
    "        pca = PCA(n_components=k)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test_pca)\n",
    "        r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    def plot_sorted_unit_tuning(ridge_clf, title='Latents \"importance\" for decoding kinematics'):\n",
    "        weights = ridge_clf.coef_\n",
    "\n",
    "        unit_importance = np.abs(weights).mean(axis=0)  # shape: (units,)\n",
    "        sorted_indices = np.argsort(-unit_importance)  # descending order\n",
    "        sorted_importance = unit_importance[sorted_indices]\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(np.arange(len(sorted_importance)), sorted_importance)\n",
    "        plt.xlabel('latent')\n",
    "        plt.ylabel('mean abs w (vx & vy)')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    pcs = np.arange(max_pcs)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(pcs, r2_scores, marker='o')\n",
    "    plt.xlabel(\"Num of PCs used for decoding\")\n",
    "    plt.ylabel(\"R²\")\n",
    "    plt.title(\"Velocity decoding from latents\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plot_sorted_unit_tuning(clf)\n",
    "\n",
    "    return np.array(r2_scores)\n",
    "\n",
    "\n",
    "r2_scores = pca_vs_r2_plot(z_s_train[:, :, :n_bins_enc, :].mean(dim=0), z_s_test[:, :, :n_bins_enc, :].mean(dim=0), vel_train, vel_test, max_pcs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHSmZrIGw-I3"
   },
   "source": [
    "# Predictive log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcxA_FBbAbzH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predictive_log_likelihood(spikes, rates):\n",
    "    eps = 1e-8\n",
    "    spikes = torch.tensor(spikes, dtype=torch.float32)\n",
    "    rates = torch.tensor(rates, dtype=torch.float32)\n",
    "\n",
    "    log_likelihood = spikes * torch.log(rates + eps) - rates\n",
    "    return log_likelihood.sum(dim=-1)\n",
    "\n",
    "\n",
    "I, T, N = y_test_obs.shape\n",
    "\n",
    "ll_filter = predictive_log_likelihood(y_test_obs.cpu(), rates_test_s).numpy()\n",
    "mean_filter = ll_filter.mean(axis=0)\n",
    "sem_filter = ll_filter.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "ll_smooth = predictive_log_likelihood(y_test_obs.cpu(), rates_test_f).numpy()\n",
    "mean_smooth = ll_smooth.mean(axis=0)\n",
    "sem_smooth = ll_smooth.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "ll_forecast = predictive_log_likelihood(y_test_obs.cpu(), rates_test_p).numpy()\n",
    "mean_forecast = ll_forecast.mean(axis=0)\n",
    "sem_forecast = ll_forecast.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "# Mean firing rate per neuron as a baseline\n",
    "mean_rate_per_neuron = y_test_obs.mean(dim=(0, 1))\n",
    "baseline_rates = mean_rate_per_neuron.unsqueeze(0).unsqueeze(0).expand(I, T, N)\n",
    "\n",
    "ll_baseline = predictive_log_likelihood(y_test_obs, baseline_rates)\n",
    "mean_base = ll_baseline.mean(dim=0).cpu().numpy()\n",
    "sem_base = ll_baseline.std(dim=0).cpu().numpy() / np.sqrt(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "6dTk4pfnxoSF",
    "outputId": "7cffb79a-ec00-4069-8a9a-b7f4f9ebe625",
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = np.arange(T) * cfg.bin_sz_ms\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(time, ll_filter.mean(0), label='Filtering', color='navy')\n",
    "plt.fill_between(time, mean_filter - sem_filter, mean_filter + sem_filter, color='navy', alpha=0.2)\n",
    "\n",
    "plt.plot(time, ll_smooth.mean(0), label='Smoothing', color='gold')\n",
    "plt.fill_between(time, mean_smooth - sem_smooth, mean_smooth + sem_smooth, color='gold', alpha=0.2)\n",
    "\n",
    "plt.plot(time, ll_forecast.mean(0), label='Forecasting', color='coral')\n",
    "plt.fill_between(time, mean_forecast - sem_forecast, mean_forecast + sem_forecast, color='coral', alpha=0.2)\n",
    "\n",
    "plt.plot(time, mean_base, label='Baseline (neuron mean fr)', color='gray')\n",
    "plt.fill_between(time,  mean_base - sem_base, mean_base + sem_base, color='gray', alpha=0.2, label='± SEM')\n",
    "\n",
    "plt.axvline(bin_prd_start * cfg.bin_sz_ms, linestyle='--', color='coral', label='prediction starts')\n",
    "\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel(r'$\\log p(y \\mid \\hat{y})$')\n",
    "plt.title('Predictive Log-Likelihood\\n\\n\\n\\n\\n')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2, fontsize='medium', frameon=False)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBI4ABQhs40K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (lvmworkshop)",
   "language": "python",
   "name": "lvmworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23999d073ec34bf68f28c909df6b166a": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_32df54d200534736aa097c81eea74e56",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 2/2  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 14/14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:38 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.36it/s</span> <span style=\"font-style: italic\">v_num: usal r2_valid_enc: -1.000    </span>\n                                                                               <span style=\"font-style: italic\">r2_valid_prd: -1.000 r2_train_enc:  </span>\n                                                                               <span style=\"font-style: italic\">-1.000 time_forward: 2.008          </span>\n</pre>\n",
         "text/plain": "Epoch 2/2  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 14/14 \u001b[2m0:00:38 • 0:00:00\u001b[0m \u001b[2;4m0.36it/s\u001b[0m \u001b[3mv_num: usal r2_valid_enc: -1.000    \u001b[0m\n                                                                               \u001b[3mr2_valid_prd: -1.000 r2_train_enc:  \u001b[0m\n                                                                               \u001b[3m-1.000 time_forward: 2.008          \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "32df54d200534736aa097c81eea74e56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
