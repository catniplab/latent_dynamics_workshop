{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdgBJgZEwQS-"
   },
   "source": [
    "# **eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling**\n",
    "\n",
    "A structured variational autoencoding framework for nonlinear state-space models capable of capturing dense covariance structures that are important for learning dynamical systems with predictive capabilities. Furthermore, when applied to neural recordings, our approach is able to learn a dynamical system capable of forecasting population spiking and behavioral correlates from a small portion of a single trial.\n",
    "\n",
    "To infer latent trajectories, XFADS leverages some quintessential properties of the exponential family distributions.\n",
    "\n",
    "This is a walk-through of some of the core functions of XFADS applied to spiking neural recordings. We will be building and training a state-space model of the [MC_Maze](https://neurallatents.github.io/datasets.html) dataset as a benchmark, which is a delayed center-out reaching task with obstructing barriers forming a maze, resulting in a variety of straight and curved reaches.\n",
    "\n",
    "With adequate configs and suitable choices of distributions for the SSM modules (as we will see below), you can fit XFADS on different spans of neural data.<br>\n",
    "\n",
    "[Dowling, Zhao, Park. 2024](https://arxiv.org/abs/2403.01371)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGXauB2Q1SGv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    _in_colab = True\n",
    "except:\n",
    "    _in_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWuhMh-rwfaV"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Create a `build-system` for the `xfads` package from the `pyproject.toml`\n",
    "\n",
    "(If you are local, make sure to run this command in the terminal after cd'íng to the project/ workshop main directory and activating the conda environment)\n",
    "\n",
    "`pip install -e xfads/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if _in_colab:\n",
    "    %cd xfads\n",
    "    !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2FW2rSzMgbf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lightning\n",
    "\n",
    "# todo, what kind of warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FD1gks9539h"
   },
   "source": [
    "# Model and training parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8AFfW4C0QDA"
   },
   "outputs": [],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "cfg = {\n",
    "    # --- graphical model --- #\n",
    "    'n_latents': 40,\n",
    "    'n_latents_read': 35,\n",
    "\n",
    "    'rank_local': 15,\n",
    "    'rank_backward': 5,\n",
    "\n",
    "    'n_hidden_dynamics': 128,\n",
    "\n",
    "    # --- inference network --- #\n",
    "    'n_samples': 25,\n",
    "    'n_hidden_local': 256,\n",
    "    'n_hidden_backward': 128,\n",
    "\n",
    "    # --- hyperparameters --- #\n",
    "    'use_cd': False,\n",
    "    'p_mask_a': 0.0,\n",
    "    'p_mask_b': 0.0,\n",
    "    'p_mask_apb': 0.0,\n",
    "    'p_mask_y_in': 0.0,\n",
    "    'p_local_dropout': 0.4,\n",
    "    'p_backward_dropout': 0.0,\n",
    "\n",
    "    # --- training --- #\n",
    "    'device': 'cpu',\n",
    "    'data_device': 'cpu',\n",
    "\n",
    "    'lr': 1e-3,\n",
    "    'lr_gamma_decay': 0.997,\n",
    "    'n_epochs': 1000,\n",
    "    'batch_sz': 128,\n",
    "\n",
    "    # --- misc --- #\n",
    "    'bin_sz': 20e-3,\n",
    "    'bin_sz_ms': 20,\n",
    "\n",
    "    'seed': 1234,\n",
    "    'default_dtype': torch.float32,\n",
    "}\n",
    "\n",
    "class Cfg(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self:\n",
    "            return self[attr]\n",
    "        else:\n",
    "            raise AttributeError(f\"'DictAsAttributes' object has no attribute '{attr}'\")\n",
    "\n",
    "cfg = Cfg(cfg)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    cfg.device = 'cpu'\n",
    "    cfg.data_device = 'cpu'\n",
    "\n",
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CnUdSdw3oh1"
   },
   "source": [
    "# Load the data\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/maze.png\"/>\n",
    "</p>\n",
    "\n",
    "**Neural activity:**\n",
    "- Binned at 20 ms\n",
    "- Covers 45 bins per trial\n",
    "- Time window: -240 ms to +660 ms relative to movement onset\n",
    "\n",
    "**Kinematics (hand velocity):**\n",
    "- binned at 20 ms\n",
    "- Covers 35 bins per trial\n",
    "- Time window: -40 ms to +660 ms relative to movement onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bg2EWDHA0xz_"
   },
   "outputs": [],
   "source": [
    "data_splits_path = './mc_maze/data/nlb'\n",
    "\n",
    "train_data = torch.load(data_splits_path + f'/data_train_{cfg.bin_sz_ms}ms.pt')\n",
    "valid_data = torch.load(data_splits_path + f'/data_valid_{cfg.bin_sz_ms}ms.pt')\n",
    "test_data = torch.load(data_splits_path + f'/data_test_{cfg.bin_sz_ms}ms.pt')\n",
    "\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKDW3TCv3xY2"
   },
   "outputs": [],
   "source": [
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_valid_obs = valid_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_valid = valid_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "print(y_train_obs.shape) # trials x time bins x neurons\n",
    "print(vel_valid.shape) # trials x time bins x vx, vy\n",
    "print(vel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_single_reaches(reaches, n_trials_to_plot):\n",
    "    trial_plt_dx = torch.randperm(reaches.shape[0])[:n_trials_to_plot]\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.suptitle('hand reaches')\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    for n in trial_plt_dx:\n",
    "        traj = torch.cumsum(reaches[n], dim=0)\n",
    "        reach_angle = torch.atan2(traj[-1, 0], traj[-1, 1])\n",
    "        reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "        ax.plot(traj[:, 0], traj[:, 1], linewidth=1.0, alpha=0.8, color=reach_color)\n",
    "            \n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_single_reaches(vel_train, n_trials_to_plot=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkjgIzeEQHZI"
   },
   "outputs": [],
   "source": [
    "move_onset_bin = 12\n",
    "\n",
    "# at t=bin_prd_start start forecast\n",
    "bin_prd_start = 10\n",
    "\n",
    "_, n_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_bins_prd = n_bins - bin_prd_start\n",
    "\n",
    "n_bins_enc = train_data['n_time_bins_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spikes_and_behavior(spikes, velocity, binsize, trials_inds, event_bin):\n",
    "    n_trials = len(trials_inds)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=n_trials, figsize=(4 * n_trials, 6), sharex=False, sharey='row')\n",
    "    if n_trials == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for col, trial_idx in enumerate(trials_inds):\n",
    "        trial = spikes[trial_idx]\n",
    "        reach = velocity[trial_idx]\n",
    "        ax_spikes = axes[0, col]\n",
    "        ax_vel = axes[1, col]\n",
    "\n",
    "        for neuron_idx in range(trial.shape[-1]):\n",
    "            spike_times = np.where(trial[:, neuron_idx].cpu() == 1)[0]\n",
    "            ax_spikes.scatter(spike_times, [neuron_idx] * len(spike_times), s=4, color='gray', marker='|')\n",
    "\n",
    "        ax_spikes.axvline(x=event_bin, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_spikes.set_ylabel('neurons')\n",
    "        ax_spikes.set_title(f'Trial {trial_idx}\\n# spikes: {int(torch.sum(trial))}', fontsize=10)\n",
    "        ax_spikes.set_xlabel('time bins')\n",
    "\n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, reach[:, 0], color='navy', label='vel x')\n",
    "        ax_vel.plot(time_axis, reach[:, 1], color='coral', label='vel y')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_vel.set_xlabel('time (ms)')\n",
    "        ax_vel.set_title('hand velocity', fontsize=10)\n",
    "        ax_vel.legend(fontsize=8)\n",
    "\n",
    "        if col == 0:\n",
    "            _, y_top = ax_spikes.get_ylim()\n",
    "            ax_spikes.annotate(\"movement\\nonset\", xy=(event_bin, y_top), xytext=(event_bin - 10, y_top + 3),\n",
    "                               arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                               fontsize=7, ha='center', alpha=0.8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_spikes_and_behavior(y_train_obs, vel_train, cfg.bin_sz_ms,\n",
    "                         torch.randperm(y_train_obs.size(0))[:4],\n",
    "                         event_bin=move_onset_bin,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D2T189rwAs-"
   },
   "outputs": [],
   "source": [
    "\"\"\"prepare data for torch\"\"\"\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJRyAgx_BUGc"
   },
   "source": [
    "# Building the State Space Model\n",
    "\n",
    "The basic elements of any state space model are:<br>\n",
    "- **Dynamics Model**, i.e. the stochastic differential equation that governs how the latents (state variables) evolve over time.\n",
    "- **Observations Model**, i.e. the data likelihood, given the latents, that governs how the state variables can generate corresponding observations.\n",
    "\n",
    "The modules to build up the state space model, to be learned by XFADS, are organized as Python classes, in a way allowing users to change and plug in their own classes that structure the elements of the model, i.e. the dynamics function, the likelihood density, and the inference network. The configuration depends on the problem: `dynamics_mod`, `initial_c_pdf`, `likelihood_pdf`, `local_encoder`, and `backward_encoder` can be configured as desired. We include some general classes in `ssm_modules/encoders`, `ssm_modules/likelihoods`, and `ssm_modules/dynamics` that should be sufficient for a wide range of problems.  Below is an example configuration.\n",
    "\n",
    "In each iteration of the Variational Inference, we need to optimize the parameters of the approximate posterior, which can be quite inefficient,\n",
    "\n",
    "To amortize the computational cost at inference time, we follow the technique of using a trainable NN, known as an **inference network** (a.k.a recognition model or \"encoder\") that outputs the posterior from the observed data.\n",
    "\n",
    "A possible drawback of the typical sequential VAEs is that they cannot naturally handle missing observations. To enable the amortized inference network to process missing observations in a principled way, we decompose the natural parameter update, of the approximate posterior, into two additive components (explained, and the intuition behind it, more in the next step). We use missing observations when masking time to encourage better forecasting.\n",
    "\n",
    "For a detailed building of XFADS, check the Method section of [the paper](https://arxiv.org/abs/2403.01371).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/ssm_diagram.png\" width=1000/>\n",
    "</p><p align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYS7gATKDTHF"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar, ModelCheckpoint\n",
    "\n",
    "import xfads.utils as utils\n",
    "import xfads.prob_utils as prob_utils\n",
    "import xfads.plot_utils as plot_utils\n",
    "\n",
    "from xfads.smoothers.nonlinear_smoother_causal import LowRankNonlinearStateSpaceModel, NonlinearFilter\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics, DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.ssm_modules.likelihoods import PoissonLikelihood\n",
    "\n",
    "from xfads.smoothers.lightning_trainers import LightningMonkeyReaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3LWqPWgoLa4"
   },
   "source": [
    "`smoothers.lightning_trainers` provides PyTorch Lightning modules for fitting state-space models to neural population activity, with support for our structured variational inference, input-driven latent dynamics, and temporally scheduled masking of observations. These modules standardize training, validation, and testing workflows, including log-likelihood computation, bits-per-spike metrics, and linear decoding of behavior from inferred firing rates or latent states.\n",
    "\n",
    "The `LightningMonkeyReaching` class is tailored for the MC Maze task, combining spiking and kinematic data from non-human primates. It supports masked training for robust inference, forward prediction from partial observations, and model selection based on R² scores from decoding hand velocity, enabling evaluation of both latent representation quality and predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLZg5XcPBTkS"
   },
   "outputs": [],
   "source": [
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"likelihood module\"\"\"\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, nn.Linear(cfg.n_latents_read, n_neurons_obs))\n",
    "likelihood_pdf = PoissonLikelihood(readout_fn, n_neurons_obs, cfg.bin_sz, device=cfg.device)\n",
    "\n",
    "\"\"\"dynamics module\"\"\"\n",
    "Q_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"initial condition\"\"\"\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)\n",
    "\n",
    "\"\"\"local/backward encoder\"\"\"\n",
    "backward_encoder = BackwardEncoderLRMvn(cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "                                        rank_local=cfg.rank_local, rank_backward=cfg.rank_backward,\n",
    "                                        device=cfg.device)\n",
    "local_encoder = LocalEncoderLRMvn(cfg.n_latents, n_neurons_obs, cfg.n_hidden_local, cfg.n_latents,rank=cfg.rank_local,\n",
    "                                  device=cfg.device, dropout=cfg.p_local_dropout)\n",
    "\n",
    "\"\"\"nonlinear filter\"\"\"\n",
    "nl_filter = NonlinearFilter(dynamics_mod, initial_condition_pdf, device=cfg.device)\n",
    "\n",
    "\"\"\"sequential vae\"\"\"\n",
    "ssm = LowRankNonlinearStateSpaceModel(dynamics_mod, likelihood_pdf, initial_condition_pdf, backward_encoder,\n",
    "                                      local_encoder, nl_filter, device=cfg.device)\n",
    "\n",
    "seq_vae = LightningMonkeyReaching(ssm, cfg, n_bins_enc, bin_prd_start)\n",
    "seq_vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UlQwxV-InRZ"
   },
   "outputs": [],
   "source": [
    "# where to save model checkpoints\n",
    "!mkdir ckpts\n",
    "# where to save training logs\n",
    "!mkdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUdGN3UVGOz6"
   },
   "outputs": [],
   "source": [
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "'''\n",
    "csv_logger = CSVLogger('./logs',\n",
    "                       name=f'sd_{cfg.seed}_r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}_mask_{cfg.p_mask_a}',\n",
    "                       version='smoother_causal')\n",
    "ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='r2_valid_enc', mode='max',\n",
    "                                dirpath=f'./ckpts/causal_mask_{cfg.p_mask_a}/', save_last=True,\n",
    "                                filename='{epoch:0}_{valid_loss:0.2f}_{r2_valid_enc:0.2f}_{r2_valid_prd:0.2f}_{valid_bps_enc:0.2f}')\n",
    "\n",
    "trainer = lightning.Trainer(max_epochs=cfg.n_epochs,\n",
    "                            accelerator='gpu',\n",
    "                            devices=1,\n",
    "                            gradient_clip_val=1.0,\n",
    "                            default_root_dir='lightning/',\n",
    "                            callbacks=[RichProgressBar(), ckpt_callback],\n",
    "                            logger=csv_logger,\n",
    "                            log_every_n_steps=1,\n",
    "                            enable_progress_bar=True)\n",
    "\n",
    "\n",
    "seq_vae.train() # Set the model to training mode before fitting\n",
    "trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "\n",
    "# Save the path to the best model\n",
    "best_model_path_saved = ckpt_callback.best_model_path\n",
    "torch.save(best_model_path_saved, f'./ckpts/causal_mask_{cfg.p_mask_a}/best_model_path.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luRtO12VJy3R"
   },
   "outputs": [],
   "source": [
    "if cfg.device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"loading the trained model\"\"\"\n",
    "best_model_path = './ckpts/smoother/epoch=827_valid_loss=1415.56_r2_valid_enc=0.89_r2_valid_bhv=0.00_valid_bps_enc=0.42.ckpt'\n",
    "seq_vae = LightningMonkeyReaching.load_from_checkpoint(best_model_path, ssm=ssm, cfg=cfg,\n",
    "                                                        n_time_bins_enc=n_bins_enc, n_time_bins_bhv=bin_prd_start,\n",
    "                                                        strict=False)\n",
    "\n",
    "seq_vae.ssm = seq_vae.ssm.to(cfg.device)\n",
    "seq_vae.ssm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5YVc6cPItcI"
   },
   "source": [
    "# Inference network\n",
    "\n",
    "Drawing inspiration from conjugate Bayesian Inference (where the prior distribution and the likelihood function are chosen such that the posterior distribution belongs to the same family as the prior distribution), the **natural parameters of the posterior** can be expressed as a sum-separable combination of the **natural parameters of the prior** and a **data-dependent term**.\n",
    "\\begin{matrix}\n",
    "\\large\\lambda_{\\phi}(z_{t-1}, y_{t:T}) = \\lambda_{\\theta}(z_{t-1}) + \\tilde\\lambda_{\\theta}(y_{t:T})\n",
    "\\end{matrix}\n",
    "\n",
    "This separation allows the approximate posterior to hold even when there are missing observations (e.g. a circuit glitch, masking, lost signal, etc). In such case, $\\tilde\\lambda_{\\theta}(y_{t})$, which we call, **the pseudo opservation $\\tilde{y}_{t}$**, can be set to zero.\n",
    "\n",
    "a **local encoder**, for current observation, and ii) a **backward encoder**, for future observations. In addition, the separation of local and backward encoders can reduce the complexity of the backward encoder for *L < N* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/smoothing.png\" width=600/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfFTrEdsJrLK"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, z_s_train, stats = seq_vae.ssm(y_train_obs, cfg.n_samples)\n",
    "    loss, z_s_valid, stats = seq_vae.ssm(y_valid_obs, cfg.n_samples)\n",
    "    loss, z_s_test, stats = seq_vae.ssm(y_test_obs, cfg.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YcmEVU7Ph4o"
   },
   "source": [
    "## Filtering\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/filtering.png\" width=600/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p23hyeEDJlbj"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, z_f_train, stats = seq_vae.ssm.forward_filter(y_train_obs, cfg.n_samples)\n",
    "    loss, z_f_valid, stats = seq_vae.ssm.forward_filter(y_valid_obs, cfg.n_samples)\n",
    "    loss, z_f_test, stats = seq_vae.ssm.forward_filter(y_test_obs, cfg.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glYgnM1oJld9"
   },
   "outputs": [],
   "source": [
    "cat_f_p= lambda f, p: torch.cat([f, p], dim=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_p_train = cat_f_p(z_f_train[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_train[:, :, bin_prd_start], n_bins_prd))\n",
    "    z_p_valid = cat_f_p(z_f_valid[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_valid[:, :, bin_prd_start], n_bins_prd))\n",
    "    z_p_test = cat_f_p(z_f_test[:, :, :bin_prd_start], seq_vae.ssm.predict_forward(z_f_test[:, :, bin_prd_start], n_bins_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rghyjRdNYrW"
   },
   "outputs": [],
   "source": [
    "\"\"\"colors\"\"\"\n",
    "blues = cm.get_cmap(\"winter\", z_s_test.shape[0])\n",
    "reds = cm.get_cmap(\"summer\", z_s_test.shape[0])\n",
    "springs = cm.get_cmap(\"spring\", z_s_test.shape[0])\n",
    "\n",
    "trial_list = [28, 202, 8, 285]\n",
    "color_map_list = [blues, reds, springs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etgfwho-NYxs"
   },
   "outputs": [],
   "source": [
    "\"\"\"smoothed latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('smoothed\\n')\n",
    "    plot_utils.plot_z_samples(fig, axs, z_s_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    axs[0].lines[-1].set_label('movement\\nonset')\n",
    "    axs[0].legend(bbox_to_anchor=(0.125, 0.96), fontsize=8, frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjrWtto-NY1-"
   },
   "outputs": [],
   "source": [
    "\"\"\"filtered latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('filtered')\n",
    "    plot_utils.plot_z_samples(fig, axs, z_f_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jch1TQxoJlgO"
   },
   "outputs": [],
   "source": [
    "\"\"\"forecasted latent states\"\"\"\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(len(trial_list), 1, figsize=(4, 4))\n",
    "    fig.suptitle('forecasted')\n",
    "    [axs[i].axvline(bin_prd_start, linestyle='--', color='red') for i in range(len(trial_list))]\n",
    "    plot_utils.plot_z_samples(fig, axs, z_p_test[:, trial_list, ..., :3].cpu(), color_map_list)\n",
    "    _, y_upper_limit = axs[0].get_ylim()\n",
    "    axs[0].annotate(f\"prediction\\nstarts\",\n",
    "                      xy=(bin_prd_start, y_upper_limit),\n",
    "                      xytext=(bin_prd_start - (n_bins * 0.1), (y_upper_limit * 1.2)),\n",
    "                      arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                      fontsize=7, alpha=0.8, ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latents_pca(z, hit_points, title=None):\n",
    "    trials, time_bins, latents = z.shape\n",
    "    data_reshaped = z.view(-1, latents).cpu().numpy()\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_result = pca.fit_transform(data_reshaped)\n",
    "    pca_result_reshaped = pca_result.reshape(trials, time_bins, 3)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "    for i, traj in enumerate(pca_result_reshaped):\n",
    "        reach_angle = np.arctan2(hit_points[i, 0], hit_points[i, 1])\n",
    "        reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "        ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], linewidth=0.8, alpha=0.6, color=reach_color)\n",
    "\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_latents_pca(\n",
    "    z_f_valid.mean(dim=0),\n",
    "    hit_points=vel_valid[:, -1, :],\n",
    "    title=\"single-trial latent trajectories (-240ms, 660ms move-onset-aligned)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "z_f_train_mean = torch.mean(z_f_train[:, :, :n_bins_enc, :], dim=0)\n",
    "trials, time_bins, latents = z_f_train_mean.shape\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(z_f_train_mean.view(-1, latents).numpy())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharex=True, sharey=True)\n",
    "fig.suptitle(\"PCs of move-aligned trials*bins x latents\", fontsize=12)\n",
    "\n",
    "angles = torch.repeat_interleave(torch.atan2(vel_train[:, -1, 0], vel_train[:, -1, 1]), repeats=vel_train.shape[-2])\n",
    "\n",
    "axes[0].scatter(pca_result[:, 0], pca_result[:, 1], s=2, alpha=0.2, c=angles, cmap='hsv', label='single time bins')\n",
    "axes[0].set_xlabel(\"PC1\")\n",
    "axes[0].set_ylabel(\"PC2\")\n",
    "\n",
    "axes[1].scatter(pca_result[:, 0], pca_result[:, 2], s=2, alpha=0.2, c=angles, cmap='hsv', label='single time bins')\n",
    "axes[1].set_xlabel(\"PC1\")\n",
    "axes[1].set_ylabel(\"PC3\")\n",
    "\n",
    "axes[2].scatter(pca_result[:, 1], pca_result[:, 2], s=2, alpha=0.2, c=angles, cmap='hsv', label='single time bins')\n",
    "axes[2].set_xlabel(\"PC2\")\n",
    "axes[2].set_ylabel(\"PC3\")\n",
    "\n",
    "plt.legend(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "z_f_train_mean = torch.mean(z_f_train, dim=0)\n",
    "trials, time_bins, latents = z_f_train_mean.shape\n",
    "\n",
    "data_reshaped = z_f_train_mean.view(-1, latents).numpy()\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(data_reshaped)\n",
    "\n",
    "pca_result_reshaped = pca_result.reshape(trials, time_bins, 3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "fig.suptitle(\"move-onset-aligned\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "for pc in range(3):\n",
    "    for trial_idx in range(trials):\n",
    "        reach_angle = torch.atan2(vel_train[trial_idx, -1, 0], vel_train[trial_idx, -1, 1])\n",
    "        reach_color = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "        axes[pc].plot(range(time_bins), pca_result_reshaped[trial_idx, :, pc], linewidth=0.2,  alpha=0.4, color=reach_color)\n",
    "\n",
    "    axes[pc].axvline(x=move_onset_bin, color='gold', alpha=0.6, linestyle='--', linewidth=0.8)\n",
    "    if pc == 0:\n",
    "        axes[pc].annotate(f\"movement\\nonset\",\n",
    "                        xy=(move_onset_bin, axes[pc].get_ylim()[1]),\n",
    "                        xytext=(move_onset_bin - (n_bins*0.1), (axes[pc].get_ylim()[1] * 1.2)),\n",
    "                        arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                        fontsize=8, alpha=0.8, ha='center')\n",
    "\n",
    "    axes[pc].set_title(f'PC{pc+1}')\n",
    "    axes[pc].set_xlabel('time bins (size 20 ms)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mc3Gvd25yOV"
   },
   "source": [
    "# Generate corresponding observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yVICHfB52jn"
   },
   "outputs": [],
   "source": [
    "rates_train_s = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_train)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_s = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_s_test)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_f = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_f_test)).mean(dim=0)).cpu().detach().numpy()\n",
    "rates_test_p = (cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_p_test)).mean(dim=0)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_trials(true_rates, generated_rates, n=4, spike_threshold=0.1):\n",
    "    true_rates = true_rates.cpu() if isinstance(true_rates, torch.Tensor) else true_rates\n",
    "    generated_rates = generated_rates.cpu() if isinstance(generated_rates, torch.Tensor) else generated_rates\n",
    "\n",
    "    trials = true_rates.shape[0]\n",
    "    n = min(n, trials)\n",
    "    random_indices = np.random.choice(trials, size=n, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, n, figsize=(2.5 * n, 8), sharex=True, sharey='row')\n",
    "\n",
    "    for idx, trial_i in enumerate(random_indices):\n",
    "        spikes = true_rates[trial_i]  # shape: [T, N]\n",
    "        T, N = spikes.shape\n",
    "\n",
    "        ax_raster = axes[0, idx]\n",
    "        spike_times, neuron_ids = np.where(spikes > spike_threshold)\n",
    "        ax_raster.scatter(spike_times, neuron_ids, s=2, color='black')\n",
    "        if idx == 0:\n",
    "            ax_raster.set_ylabel(\"neuron\")\n",
    "\n",
    "        ax_gen = axes[1, idx]\n",
    "        im = ax_gen.imshow(generated_rates[trial_i].T, aspect='auto', cmap='viridis', origin='lower')\n",
    "        if idx == 0:\n",
    "            ax_gen.set_ylabel(\"neuron\")\n",
    "            ax_gen.set_xlabel(\"time bins\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([1., 0.12, 0.015, 0.33])  # [left, bottom, width, height]\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"firing rate\")\n",
    "\n",
    "    axes[0, 0].set_title(\"Observed spikes (raster)\", fontsize=12)\n",
    "    axes[1, 0].set_title(\"Generated firing rates\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_trials(y_test_obs, rates_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructed single-neuron firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neurons_to_plot = 16\n",
    "neuron_indcs = np.random.choice(range(0, y_test_obs.shape[2]), size=n_neurons_to_plot, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(int(np.sqrt(n_neurons_to_plot)), int(np.sqrt(n_neurons_to_plot)), figsize=(14, 10))\n",
    "fig.suptitle(f'Trial-averaged neurons activity\\n\\n\\n\\n')\n",
    "\n",
    "for ax, neuron in zip(axes.flat, neuron_indcs):\n",
    "\n",
    "    fr_data = torch.mean(y_test_obs[:, :, neuron], axis=0).cpu()\n",
    "    fr_model_s = torch.mean(torch.from_numpy(rates_test_s[:, :, neuron]), axis=0)\n",
    "    fr_model_p = torch.mean(torch.from_numpy(rates_test_p[:, :, neuron]), axis=0)\n",
    "\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_data, color= 'black', alpha=0.8, label='true' if neuron == neuron_indcs[-1] else '')\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_model_s, color= 'green', alpha=1.0, label='smoothed' if neuron == neuron_indcs[-1] else '')\n",
    "    ax.plot(np.arange(n_bins) * cfg.bin_sz_ms, fr_model_p, color= 'coral', alpha=1.0, label='forecasted' if neuron == neuron_indcs[-1] else '')\n",
    "\n",
    "    ax.axvline(bin_prd_start * cfg.bin_sz_ms, linestyle='--', color= 'coral')\n",
    "    ax.axvline(move_onset_bin * cfg.bin_sz_ms, linestyle='--', color= 'gray')\n",
    "\n",
    "    if neuron == neuron_indcs[0]:\n",
    "      _, y_upper_limit = ax.get_ylim()\n",
    "      ax.annotate(f\"prediction\\nstarts\",\n",
    "                      xy=(bin_prd_start * cfg.bin_sz_ms, y_upper_limit),\n",
    "                      xytext=(bin_prd_start * cfg.bin_sz_ms - (n_bins * 0.3), (y_upper_limit * 1.2)),\n",
    "                      arrowprops=dict(facecolor='black', alpha=0.2, arrowstyle='->'),\n",
    "                      fontsize=7, alpha=0.8, ha='center')\n",
    "\n",
    "    ax.set_title(f'\\nneuron {neuron+1}\\n', fontsize=8)\n",
    "    ax.set_xlabel('time (ms)' if neuron == neuron_indcs[-int(np.sqrt(n_neurons_to_plot))] else '', fontsize=9)\n",
    "    ax.set_ylabel('firing rate' if neuron == neuron_indcs[0] else '', fontsize=9)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0.94), ncol=1, fontsize=8)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npBXlAmOGQQy"
   },
   "source": [
    "# Decoding hand kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RZxxe1VGWpW"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ka1zFLJWks2t"
   },
   "outputs": [],
   "source": [
    "\"\"\"velocity decoder\"\"\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    clf = Ridge(alpha=0.01)\n",
    "\n",
    "    clf.fit(rates_train_s[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), vel_train.cpu().reshape(-1, 2))\n",
    "    r2 = clf.score(rates_train_s[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), vel_train.cpu().reshape(-1, 2))\n",
    "\n",
    "    pred_reshape = lambda rates, clf, original_shape: clf.predict(rates[:, :n_bins_enc, :].reshape(-1, n_neurons_obs)).reshape(list(original_shape)[:-1] + [2])\n",
    "    calc_r2 = lambda rates, clf, true_velocity: clf.score(rates[:, :n_bins_enc, :].reshape(-1, n_neurons_obs), true_velocity.cpu().reshape(-1, 2))\n",
    "\n",
    "    r2_test_s = calc_r2(rates_test_s, clf, vel_test)\n",
    "    r2_test_f = calc_r2(rates_test_f, clf, vel_test)\n",
    "    r2_test_p = calc_r2(rates_test_p, clf, vel_test)\n",
    "\n",
    "    vel_hat_test_s = pred_reshape(rates_test_s, clf, vel_test.shape)\n",
    "    vel_hat_test_f = pred_reshape(rates_test_f, clf, vel_test.shape)\n",
    "    vel_hat_test_p = pred_reshape(rates_test_p, clf, vel_test.shape)\n",
    "\n",
    "n_trials_test = vel_test.shape[0]\n",
    "n_trials_plot = 35\n",
    "\n",
    "vel_to_pos = lambda v: torch.cumsum(torch.tensor(v).clone().detach().to('cpu'), dim=1)\n",
    "\n",
    "pos_test = vel_to_pos(vel_test.cpu())\n",
    "trial_plt_dx = torch.randperm(n_trials_test)[:n_trials_plot]\n",
    "reach_angle = torch.atan2(pos_test[:, -1, 0], pos_test[:, -1, 1])\n",
    "reach_colors = plt.cm.hsv(reach_angle / (2 * np.pi) + 0.5)\n",
    "\n",
    "pos_test_hat_s = vel_to_pos(vel_hat_test_s)\n",
    "pos_test_hat_f = vel_to_pos(vel_hat_test_f)\n",
    "pos_test_hat_p = vel_to_pos(vel_hat_test_p)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "    plot_utils.plot_reaching(axs[0], pos_test[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[1], pos_test_hat_s[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[2], pos_test_hat_f[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "    plot_utils.plot_reaching(axs[3], pos_test_hat_p[trial_plt_dx], reach_colors[trial_plt_dx])\n",
    "\n",
    "    axs[0].set_title('true')\n",
    "    axs[1].set_title(f'smoothed, r2:{r2_test_s:.3f}')\n",
    "    axs[2].set_title(f'filtered, r2:{r2_test_f:.3f}')\n",
    "    axs[3].set_title(f'predicted, r2:{r2_test_p:.3f}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_spikes_and_decoded_behavior(spikes, velocity, velocity_hat, binsize, trials_inds, event_bin):\n",
    "    n_trials = len(trials_inds)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=n_trials, figsize=(4 * n_trials, 6), sharex=False, sharey='row')\n",
    "    if n_trials == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for col, trial_idx in enumerate(trials_inds):\n",
    "        trial = spikes[trial_idx]\n",
    "        reach = velocity[trial_idx]\n",
    "        decoded_reach = velocity_hat[trial_idx]\n",
    "        ax_spikes = axes[0, col]\n",
    "        ax_vel = axes[1, col]\n",
    "\n",
    "        for neuron_idx in range(trial.shape[-1]):\n",
    "            spike_times = np.where(trial[:, neuron_idx].cpu() == 1)[0]\n",
    "            ax_spikes.scatter(spike_times, [neuron_idx] * len(spike_times), s=4, color='gray', marker='|')\n",
    "\n",
    "        ax_spikes.axvline(x=event_bin, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_spikes.set_ylabel('neurons')\n",
    "        ax_spikes.set_title(f'\\nTrial {trial_idx}\\n# spikes: {int(torch.sum(trial))}', fontsize=10)\n",
    "        ax_spikes.set_xlabel('time bins')\n",
    "\n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, reach[:, 0], color='navy', label='true vel x' if col == 0 else '')\n",
    "        ax_vel.plot(time_axis, reach[:, 1], color='coral', label='true vel y' if col == 0 else '')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_vel.set_xlabel('time (ms)')\n",
    "        ax_vel.set_title('hand velocity', fontsize=10)\n",
    "        \n",
    "        time_axis = torch.arange(reach.shape[0]) * binsize\n",
    "        ax_vel.plot(time_axis, decoded_reach[:, 0], linestyle='--', color='navy', label='decoded vel x' if col == 0 else '')\n",
    "        ax_vel.plot(time_axis, decoded_reach[:, 1], linestyle='--', color='coral', label='decoded vel y' if col == 0 else '')\n",
    "        ax_vel.axvline(x=event_bin * binsize, linestyle='--', color='purple', alpha=0.4)\n",
    "        ax_vel.set_xlabel('time (ms)')\n",
    "        ax_vel.set_title('hand velocity', fontsize=10)\n",
    "\n",
    "        if col == 0:\n",
    "            _, y_top = ax_spikes.get_ylim()\n",
    "            ax_spikes.annotate(\"movement\\nonset\", xy=(event_bin, y_top), xytext=(event_bin - 10, y_top + 3),\n",
    "                               arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "                               fontsize=7, ha='center', alpha=0.8)\n",
    "            \n",
    "    fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=2, fontsize=10, frameon=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_spikes_and_decoded_behavior(y_test_obs, vel_test, vel_hat_test_s, cfg.bin_sz_ms,\n",
    "                                 torch.randperm(y_test_obs.size(0))[:4],\n",
    "                                 event_bin=move_onset_bin,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea1D2PwnSNSe"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    r2_k_step = []\n",
    "    for k in range(n_bins):\n",
    "\n",
    "        z_prd_test = utils.propagate_latent_k_steps(z_f_test[:, :, k], dynamics_mod, n_bins - (k + 1))\n",
    "        z_prd_test = torch.concat([z_f_test[:, :, :k], z_prd_test], dim=2)\n",
    "\n",
    "        rates_prd_test = cfg.bin_sz * torch.exp(seq_vae.ssm.likelihood_pdf.readout_fn(z_prd_test)).mean(dim=0).cpu().detach().numpy()\n",
    "        r2_prd = calc_r2(rates_prd_test, clf, vel_test)\n",
    "        r2_k_step.append(r2_prd)\n",
    "\n",
    "plt.axvline(move_onset_bin, linestyle='--')\n",
    "plt.annotate(f\"movement\\nonset\",\n",
    "             xy=(move_onset_bin, y_upper_limit),\n",
    "             xytext=(move_onset_bin + (n_bins * 0.15), (y_upper_limit * 1.2)),\n",
    "             arrowprops=dict(facecolor='black', alpha=0.4, arrowstyle='->'),\n",
    "             fontsize=7, alpha=0.8, ha='center')\n",
    "\n",
    "plt.plot(r2_k_step)\n",
    "plt.axhline(r2_test_s, color='green', label='smoothed')\n",
    "plt.axhline(r2_test_f, color='orange', label='filtered')\n",
    "plt.xlabel('bin prd start')\n",
    "plt.ylabel('r2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlV-9xtihHrb"
   },
   "source": [
    "Evaluating how well future hand velocity can be decoded from the model's predictions when starting the prediction from different points in the trial (k). This analysis assesses how the model's ability to forecast the remaining hand movement changes depending on how much of the initial trial data it has observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_vs_r2_plot(z_train, z_test, vel_train, vel_test, max_pcs=30, alpha=0.01):\n",
    "    def flatten(x):\n",
    "        return x.reshape(-1, x.shape[2]).detach().cpu().numpy()\n",
    "\n",
    "    def flatten_vel(v):\n",
    "        return v.reshape(-1, 2).detach().cpu().numpy()\n",
    "\n",
    "    X_train = flatten(z_train)\n",
    "    X_test = flatten(z_test)\n",
    "    y_train = flatten_vel(vel_train)\n",
    "    y_test = flatten_vel(vel_test)\n",
    "\n",
    "    r2_scores = []\n",
    "\n",
    "    for k in range(1, max_pcs + 1):\n",
    "        pca = PCA(n_components=k)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        clf = Ridge(alpha=alpha)\n",
    "        clf.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test_pca)\n",
    "        r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "    def plot_sorted_unit_tuning(ridge_clf, title='Latents \"importance\" for decoding kinematics'):\n",
    "        weights = ridge_clf.coef_\n",
    "\n",
    "        unit_importance = np.abs(weights).mean(axis=0)  # shape: (units,)\n",
    "        sorted_indices = np.argsort(-unit_importance)  # descending order\n",
    "        sorted_importance = unit_importance[sorted_indices]\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(np.arange(len(sorted_importance)), sorted_importance)\n",
    "        plt.xlabel('latent')\n",
    "        plt.ylabel('mean abs w (vx & vy)')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    pcs = np.arange(max_pcs)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(pcs, r2_scores, marker='o')\n",
    "    plt.xlabel(\"Num of PCs used for decoding\")\n",
    "    plt.ylabel(\"R²\")\n",
    "    plt.title(\"Velocity decoding from latents\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plot_sorted_unit_tuning(clf)\n",
    "\n",
    "    return np.array(r2_scores)\n",
    "\n",
    "\n",
    "r2_scores = pca_vs_r2_plot(z_s_train[:, :, :n_bins_enc, :].mean(dim=0), z_s_test[:, :, :n_bins_enc, :].mean(dim=0), vel_train, vel_test, max_pcs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHSmZrIGw-I3"
   },
   "source": [
    "# Predictive log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcxA_FBbAbzH"
   },
   "outputs": [],
   "source": [
    "def predictive_log_likelihood(spikes, rates):\n",
    "    eps = 1e-8\n",
    "    spikes = torch.tensor(spikes, dtype=torch.float32)\n",
    "    rates = torch.tensor(rates, dtype=torch.float32)\n",
    "\n",
    "    log_likelihood = spikes * torch.log(rates + eps) - rates\n",
    "    return log_likelihood.sum(dim=-1)\n",
    "\n",
    "\n",
    "I, T, N = y_test_obs.shape\n",
    "\n",
    "ll_filter = predictive_log_likelihood(y_test_obs.cpu(), rates_test_s).numpy()\n",
    "mean_filter = ll_filter.mean(axis=0)\n",
    "sem_filter = ll_filter.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "ll_smooth = predictive_log_likelihood(y_test_obs.cpu(), rates_test_f).numpy()\n",
    "mean_smooth = ll_smooth.mean(axis=0)\n",
    "sem_smooth = ll_smooth.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "ll_forecast = predictive_log_likelihood(y_test_obs.cpu(), rates_test_p).numpy()\n",
    "mean_forecast = ll_forecast.mean(axis=0)\n",
    "sem_forecast = ll_forecast.std(axis=0) / np.sqrt(I)\n",
    "\n",
    "# Mean firing rate per neuron as a baseline\n",
    "mean_rate_per_neuron = y_test_obs.mean(dim=(0, 1))\n",
    "baseline_rates = mean_rate_per_neuron.unsqueeze(0).unsqueeze(0).expand(I, T, N)\n",
    "\n",
    "ll_baseline = predictive_log_likelihood(y_test_obs, baseline_rates)\n",
    "mean_base = ll_baseline.mean(dim=0).cpu().numpy()\n",
    "sem_base = ll_baseline.std(dim=0).cpu().numpy() / np.sqrt(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dTk4pfnxoSF"
   },
   "outputs": [],
   "source": [
    "time = np.arange(T) * cfg.bin_sz_ms\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(time, ll_filter.mean(0), label='Filtering', color='navy')\n",
    "plt.fill_between(time, mean_filter - sem_filter, mean_filter + sem_filter, color='navy', alpha=0.2)\n",
    "\n",
    "plt.plot(time, ll_smooth.mean(0), label='Smoothing', color='gold')\n",
    "plt.fill_between(time, mean_smooth - sem_smooth, mean_smooth + sem_smooth, color='gold', alpha=0.2)\n",
    "\n",
    "plt.plot(time, ll_forecast.mean(0), label='Forecasting', color='coral')\n",
    "plt.fill_between(time, mean_forecast - sem_forecast, mean_forecast + sem_forecast, color='coral', alpha=0.2)\n",
    "\n",
    "plt.plot(time, mean_base, label='Baseline (neuron mean fr)', color='gray')\n",
    "plt.fill_between(time,  mean_base - sem_base, mean_base + sem_base, color='gray', alpha=0.2, label='± SEM')\n",
    "\n",
    "plt.axvline(bin_prd_start * cfg.bin_sz_ms, linestyle='--', color='coral', label='prediction starts')\n",
    "\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel(r'$\\log p(y \\mid \\hat{y})$')\n",
    "plt.title('Predictive Log-Likelihood\\n\\n\\n\\n\\n')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2, fontsize='medium', frameon=False)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (lvmworkshop)",
   "language": "python",
   "name": "lvmworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
